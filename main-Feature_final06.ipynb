{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport scipy.io\nimport numpy as np\nfrom scipy import signal\n\n# Set the path to the root directory where the \"Control\" folder is located\ndata_path = \"/kaggle/input/control1\"\nlowcut = 0.4 \nhighcut = 100 \nfs_original = 500\nfs_new = 250\n\ncontrol_data = []\ncontrol_path = os.path.join(data_path, 'Control')\n\nfor foldername in os.listdir(control_path):\n    subfolder_path = os.path.join(control_path, foldername)\n    control_data.append(subfolder_path)\n\nControl30 = []\n\nfor control_data_path in control_data:\n    n_epochs = 105#len([f for f in os.listdir(control_data_path) if f.endswith('.mat')])\n    control_arr = []\n    \n    for i in range(1, n_epochs+1):\n        epoch_path = os.path.join(control_data_path, f\"trial{i}.mat\")\n        mat_data = scipy.io.loadmat(epoch_path)\n        mat_data1 = mat_data[\"trialData_i\"]\n                # Average referencing\n#         average_potential = np.mean(mat_data1, axis=0, keepdims=True)\n#         referenced_data = mat_data1 - average_potential\n        \n#         # Bandpass filtering\n#         b, a = signal.butter(4, [lowcut, highcut], fs=fs_original, btype='band')\n#         filtered_data = signal.filtfilt(b, a, referenced_data, axis=-1)\n        \n#         # Apply notch filter\n#         f0 = 60  # Frequency to be removed (e.g., power line interference)\n#         Q = 30   # Quality factor\n#         w0 = f0 / (fs_original / 2)\n#         b, a = signal.iirnotch(w0, Q)\n#         filtered_data = signal.filtfilt(b, a, filtered_data, axis=-1)\n\n        \n        # Downsampling\n        num_samples_original = mat_data1.shape[-1]\n        num_samples_new = int(num_samples_original * fs_new / fs_original)\n        downsampled_data = signal.resample(mat_data1, num_samples_new, axis=-1)\n        \n        control_arr.append(np.array(downsampled_data))\n        \n    Control30.append(np.array(control_arr))\n\nControl30 = np.array(Control30)\nprint(Control30[0].shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:03:23.075814Z","iopub.execute_input":"2023-06-11T14:03:23.076191Z","iopub.status.idle":"2023-06-11T14:04:05.081193Z","shell.execute_reply.started":"2023-06-11T14:03:23.076161Z","shell.execute_reply":"2023-06-11T14:04:05.079952Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"(105, 60, 1000)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.stats import entropy\n\ndelta_band = (0.5, 4)\nalpha_band = (8, 12)\nbeta_band = (12, 35)\n\nall_control_power = []\nscaler = MinMaxScaler()\nepsilon = 1e-10\n\n# Normalizing the features\nfor i in range(len(Control30)):\n    control_data = Control30[i]\n    control_power = []\n    for epoch in control_data:\n        epoch_power = []\n        for channel_data in epoch:\n            freq_spectrum = np.fft.fft(channel_data)\n            power_spectrum = np.abs(freq_spectrum) ** 2\n\n            alpha_power = np.sum(power_spectrum[(alpha_band[0] <= freq_spectrum) & (freq_spectrum <= alpha_band[1])])\n            beta_power = np.sum(power_spectrum[(beta_band[0] <= freq_spectrum) & (freq_spectrum <= beta_band[1])])\n            delta_power = np.sum(power_spectrum[(delta_band[0] <= freq_spectrum) & (freq_spectrum <= delta_band[1])])\n\n            channel_min_value = np.min(channel_data)\n            channel_max_value = np.max(channel_data)\n\n            # alpha_power_normalized = (alpha_power - channel_min_value) / (4*((channel_max_value-channel_min_value) * (channel_max_value-channel_min_value )))\n            # beta_power_normalized = (beta_power - channel_min_value) /  (4*((channel_max_value-channel_min_value) * (channel_max_value-channel_min_value) ))\n            # delta_power_normalized = (delta_power - channel_min_value) /  (4*((channel_max_value-channel_min_value) * (channel_max_value-channel_min_value)))\n\n            power_spectrum_adjusted = power_spectrum + epsilon\n            entropy_values = entropy(power_spectrum_adjusted)\n            values=np.array([alpha_power,beta_power,delta_power,entropy_values])\n            rescaled_values = (values - values.min()) * (channel_max_value - channel_min_value) / (values.max() - values.min()) + channel_min_value\n            concatenated_data = np.concatenate((channel_data, rescaled_values))\n\n            #concatenated_data = np.concatenate((channel_data, [alpha_power_normalized, beta_power_normalized, delta_power_normalized, entropy_values]))\n            #print(alpha_power_normalized, beta_power_normalized, delta_power_normalized, entropy_values)\n            epoch_power.append(concatenated_data.tolist())\n\n        control_power.append(np.array(epoch_power))\n\n    all_control_power.append(np.array(control_power))\n\nall_control_power = np.array(all_control_power)\nprint(all_control_power.shape)\nprint(len(Control30))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:04:05.083358Z","iopub.execute_input":"2023-06-11T14:04:05.083677Z","iopub.status.idle":"2023-06-11T14:04:52.743158Z","shell.execute_reply.started":"2023-06-11T14:04:05.083655Z","shell.execute_reply":"2023-06-11T14:04:52.742032Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(30, 105, 60, 1004)\n30\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport scipy.io\nimport numpy as np\nfrom scipy import signal\ndata_path = \"/kaggle/input/concussed1\"\nlowcut = 0.4 \nhighcut = 100 \nfs_original = 500\nfs_new = 250  \n\nconcussed_data = []\nconcussed_path = os.path.join(data_path, 'Concussed')\nfor foldername in os.listdir(concussed_path):\n    subfolder_path = os.path.join(concussed_path, foldername)\n    concussed_data.append(subfolder_path)\n\nConcussed52 = []\nfor concussed_data_path in concussed_data:\n    n_epochs = 105 #len([f for f in os.listdir(control_data_path) if f.endswith('.mat')])\n    concussed_arr = []\n    for i in range(1, n_epochs+1):\n        epoch_path = f\"{concussed_data_path}/trial{i}.mat\"\n        mat_data = scipy.io.loadmat(epoch_path)\n        mat_data1 = mat_data[\"trialData_i\"]\n#         # Average referencing\n#         average_potential = np.mean(mat_data1, axis=0, keepdims=True)\n#         referenced_data = mat_data1 - average_potential\n        \n#         # Bandpass filtering\n#         b, a = signal.butter(4, [lowcut, highcut], fs=fs_original, btype='band')\n#         filtered_data = signal.filtfilt(b, a, referenced_data, axis=-1)\n        \n#         # Apply notch filter\n#         f0 = 60  # Frequency to be removed (e.g., power line interference)\n#         Q = 30   # Quality factor\n#         w0 = f0 / (fs_original / 2)\n#         b, a = signal.iirnotch(w0, Q)\n#         filtered_data = signal.filtfilt(b, a, filtered_data, axis=-1)\n        \n        # Downsampling\n        num_samples_original = mat_data1.shape[-1]\n        num_samples_new = int(num_samples_original * fs_new / fs_original)\n        downsampled_data = signal.resample(mat_data1, num_samples_new, axis=-1)\n        \n        concussed_arr.append(np.array(downsampled_data))\n        \n    Concussed52.append(np.array(concussed_arr))\n\nConcussed52 = np.array(Concussed52)\nprint( Concussed52[0].shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:04:52.744841Z","iopub.execute_input":"2023-06-11T14:04:52.745345Z","iopub.status.idle":"2023-06-11T14:05:52.437350Z","shell.execute_reply.started":"2023-06-11T14:04:52.745319Z","shell.execute_reply":"2023-06-11T14:05:52.435948Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(105, 60, 1000)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom scipy.stats import entropy\n\ndelta_band = (0.5, 4)\nalpha_band = (8, 12)\nbeta_band = (12, 35)\n\nall_concussed_power = []\nscaler = MinMaxScaler()\nepsilon = 1e-10\n\n# Normalizing the features within the range of the minimum and maximum values of the corresponding channel\nfor i in range(len(Concussed52)):\n    concussed_data = Concussed52[i]\n    concussed_power = []\n    for epoch in concussed_data:\n        epoch_power = []\n        for channel_data in epoch:\n            freq_spectrum = np.fft.fft(channel_data)\n            power_spectrum = np.abs(freq_spectrum) ** 2\n\n            alpha_power = np.sum(power_spectrum[(alpha_band[0] <= freq_spectrum) & (freq_spectrum <= alpha_band[1])])\n            beta_power = np.sum(power_spectrum[(beta_band[0] <= freq_spectrum) & (freq_spectrum <= beta_band[1])])\n            delta_power = np.sum(power_spectrum[(delta_band[0] <= freq_spectrum) & (freq_spectrum <= delta_band[1])])\n\n            channel_min_value = np.min(channel_data)\n            channel_max_value = np.max(channel_data)\n\n            # alpha_power_normalized = (alpha_power - channel_min_value) / (4*((channel_max_value-channel_min_value) * (channel_max_value-channel_min_value )))\n            # beta_power_normalized = (beta_power - channel_min_value) /  (4*((channel_max_value-channel_min_value) * (channel_max_value-channel_min_value) ))\n            # delta_power_normalized = (delta_power - channel_min_value) /  (4*((channel_max_value-channel_min_value) * (channel_max_value-channel_min_value)))\n\n            power_spectrum_adjusted = power_spectrum + epsilon\n            entropy_values = entropy(power_spectrum_adjusted)\n            values=np.array([alpha_power,beta_power,delta_power,entropy_values])\n            rescaled_values = (values - values.min()) * (channel_max_value - channel_min_value) / (values.max() - values.min()) + channel_min_value\n            concatenated_data = np.concatenate((channel_data, rescaled_values))\n\n            #concatenated_data = np.concatenate((channel_data, [alpha_power_normalized, beta_power_normalized, delta_power_normalized, entropy_values]))\n            #print(alpha_power_normalized, beta_power_normalized, delta_power_normalized, entropy_values)\n            epoch_power.append(concatenated_data.tolist())\n\n        concussed_power.append(np.array(epoch_power))\n\n    all_concussed_power.append(np.array(concussed_power))\n\nall_concussed_power = np.array(all_concussed_power)\nprint(all_concussed_power.shape)\nprint(len(Concussed52))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:05:52.439088Z","iopub.execute_input":"2023-06-11T14:05:52.439423Z","iopub.status.idle":"2023-06-11T14:07:10.924327Z","shell.execute_reply.started":"2023-06-11T14:05:52.439393Z","shell.execute_reply":"2023-06-11T14:07:10.922767Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(49, 105, 60, 1004)\n49\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = np.concatenate((all_control_power, all_concussed_power), axis=0)\nlabels = np.concatenate((np.zeros(len(all_control_power)), np.ones(len(all_concussed_power))))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:10.930138Z","iopub.execute_input":"2023-06-11T14:07:10.930549Z","iopub.status.idle":"2023-06-11T14:07:11.622076Z","shell.execute_reply.started":"2023-06-11T14:07:10.930514Z","shell.execute_reply":"2023-06-11T14:07:11.620429Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# num_control_samples = len(all_control_power)\n# num_concussed_samples = len(all_concussed_power)\n\n# # Randomly select a subset of samples from the larger class\n# undersampled_concussed_indices = np.random.choice(\n#     num_concussed_samples, size=num_control_samples, replace=False\n# )\n# undersampled_concussed_power = all_concussed_power[undersampled_concussed_indices]\n# undersampled_concussed_labels = labels[num_control_samples:][undersampled_concussed_indices]\n\n# # Combine the undersampled concussed data with the original control data\n# undersampled_data = np.concatenate((all_control_power, undersampled_concussed_power), axis=0)\n# undersampled_labels = np.concatenate((labels[:num_control_samples], undersampled_concussed_labels), axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:11.623548Z","iopub.execute_input":"2023-06-11T14:07:11.623861Z","iopub.status.idle":"2023-06-11T14:07:11.628729Z","shell.execute_reply.started":"2023-06-11T14:07:11.623837Z","shell.execute_reply":"2023-06-11T14:07:11.627673Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# print(undersampled_concussed_power.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:11.629949Z","iopub.execute_input":"2023-06-11T14:07:11.630823Z","iopub.status.idle":"2023-06-11T14:07:11.646104Z","shell.execute_reply.started":"2023-06-11T14:07:11.630795Z","shell.execute_reply":"2023-06-11T14:07:11.644572Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(dataset, labels, test_size=0.1, random_state=42)\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"X_val shape:\", X_val.shape)\nprint(\"y_val shape:\", y_val.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:11.647575Z","iopub.execute_input":"2023-06-11T14:07:11.647884Z","iopub.status.idle":"2023-06-11T14:07:12.557562Z","shell.execute_reply.started":"2023-06-11T14:07:11.647860Z","shell.execute_reply":"2023-06-11T14:07:12.555801Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"X_train shape: (71, 105, 60, 1004)\ny_train shape: (71,)\nX_val shape: (8, 105, 60, 1004)\ny_val shape: (8,)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\ncallback_list = EarlyStopping(\n        monitor='val_loss',\n        patience=20,\n        restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:12.559273Z","iopub.execute_input":"2023-06-11T14:07:12.559590Z","iopub.status.idle":"2023-06-11T14:07:15.468004Z","shell.execute_reply.started":"2023-06-11T14:07:12.559567Z","shell.execute_reply":"2023-06-11T14:07:15.466592Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\n\ninput_shape = (105, 60, 1004)\n\nmodel = tf.keras.Sequential()\nmodel.add(layers.Conv2D(16, kernel_size=(3, 3), strides=2, activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=l2(0.01)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Conv2D(32, kernel_size=(3, 3), strides=2, activation='relu', padding='same', kernel_regularizer=l2(0.01)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:15.470317Z","iopub.execute_input":"2023-06-11T14:07:15.471300Z","iopub.status.idle":"2023-06-11T14:07:15.931827Z","shell.execute_reply.started":"2023-06-11T14:07:15.471260Z","shell.execute_reply":"2023-06-11T14:07:15.931188Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 53, 30, 16)        144592    \n                                                                 \n batch_normalization (BatchN  (None, 53, 30, 16)       64        \n ormalization)                                                   \n                                                                 \n dropout (Dropout)           (None, 53, 30, 16)        0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 27, 15, 32)        4640      \n                                                                 \n batch_normalization_1 (Batc  (None, 27, 15, 32)       128       \n hNormalization)                                                 \n                                                                 \n dropout_1 (Dropout)         (None, 27, 15, 32)        0         \n                                                                 \n flatten (Flatten)           (None, 12960)             0         \n                                                                 \n dense (Dense)               (None, 128)               1659008   \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 1)                 129       \n                                                                 \n=================================================================\nTotal params: 1,808,561\nTrainable params: 1,808,465\nNon-trainable params: 96\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    loss='binary_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:15.932884Z","iopub.execute_input":"2023-06-11T14:07:15.933127Z","iopub.status.idle":"2023-06-11T14:07:15.956213Z","shell.execute_reply.started":"2023-06-11T14:07:15.933105Z","shell.execute_reply":"2023-06-11T14:07:15.954963Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\nX = dataset\ny = labels\nEpoch = 200\nbatchSize = 16\n\nk_folds = 6\nkf = KFold(n_splits=k_folds, shuffle=True)\n\ntrain_accuracies = []\nval_accuracies = []\ncm_total = np.zeros((2, 2))  \ny_preds = []  \n\n# cross-validation\nfor train_index, val_index in kf.split(X):\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n\n    history = model.fit(\n        X_train,\n        y_train,\n        epochs=Epoch,\n        batch_size=batchSize,\n        validation_data=(X_val, y_val),\n        callbacks=callback_list,\n        verbose=1)\n\n    train_loss, train_accuracy = model.evaluate(X_train, y_train)\n    val_loss, val_accuracy = model.evaluate(X_val, y_val)\n\n    train_accuracies.append(train_accuracy)\n    val_accuracies.append(val_accuracy)\n\n    y_pred = model.predict(X_val)\n    y_pred = np.round(y_pred).flatten()\n    y_preds.append(y_pred)\n\n    cm = confusion_matrix(y_val, y_pred)\n    cm_total += cm\n\navg_train_accuracy = np.mean(train_accuracies)\navg_val_accuracy = np.mean(val_accuracies)\ncm_avg = cm_total / k_folds\n\ny_preds = np.concatenate(y_preds)\n\nprint('Confusion Matrix')\nprint(cm_avg)\nprint('\\n')\n\n# Define target names\ntarget_names = ['Control', 'Concussed']\n\n# Calculate classification report\nprint('Classification Report')\nprint(classification_report(y, y_preds, target_names=target_names))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:07:15.958095Z","iopub.execute_input":"2023-06-11T14:07:15.958522Z","iopub.status.idle":"2023-06-11T14:58:34.369062Z","shell.execute_reply.started":"2023-06-11T14:07:15.958461Z","shell.execute_reply":"2023-06-11T14:58:34.366250Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/200\n5/5 [==============================] - 5s 680ms/step - loss: 4.1921 - accuracy: 0.4462 - val_loss: 3.7193 - val_accuracy: 0.5714\nEpoch 2/200\n5/5 [==============================] - 2s 496ms/step - loss: 4.0432 - accuracy: 0.5077 - val_loss: 3.7327 - val_accuracy: 0.5714\nEpoch 3/200\n5/5 [==============================] - 2s 487ms/step - loss: 3.8810 - accuracy: 0.5692 - val_loss: 3.7305 - val_accuracy: 0.6429\nEpoch 4/200\n5/5 [==============================] - 2s 494ms/step - loss: 3.7068 - accuracy: 0.7077 - val_loss: 3.6712 - val_accuracy: 0.7143\nEpoch 5/200\n5/5 [==============================] - 2s 496ms/step - loss: 3.9609 - accuracy: 0.5538 - val_loss: 3.6367 - val_accuracy: 0.7143\nEpoch 6/200\n5/5 [==============================] - 2s 497ms/step - loss: 3.8144 - accuracy: 0.6154 - val_loss: 3.6252 - val_accuracy: 0.6429\nEpoch 7/200\n5/5 [==============================] - 3s 520ms/step - loss: 3.8467 - accuracy: 0.6308 - val_loss: 3.6172 - val_accuracy: 0.6429\nEpoch 8/200\n5/5 [==============================] - 3s 492ms/step - loss: 3.6093 - accuracy: 0.7692 - val_loss: 3.6255 - val_accuracy: 0.6429\nEpoch 9/200\n5/5 [==============================] - 3s 503ms/step - loss: 3.6192 - accuracy: 0.6615 - val_loss: 3.6338 - val_accuracy: 0.6429\nEpoch 10/200\n5/5 [==============================] - 3s 500ms/step - loss: 3.7732 - accuracy: 0.6154 - val_loss: 3.6450 - val_accuracy: 0.6429\nEpoch 11/200\n5/5 [==============================] - 2s 498ms/step - loss: 3.6335 - accuracy: 0.7231 - val_loss: 3.6566 - val_accuracy: 0.5714\nEpoch 12/200\n5/5 [==============================] - 2s 494ms/step - loss: 3.8381 - accuracy: 0.6462 - val_loss: 3.6663 - val_accuracy: 0.5714\nEpoch 13/200\n5/5 [==============================] - 3s 496ms/step - loss: 3.5536 - accuracy: 0.7538 - val_loss: 3.6532 - val_accuracy: 0.5714\nEpoch 14/200\n5/5 [==============================] - 3s 504ms/step - loss: 3.6065 - accuracy: 0.6769 - val_loss: 3.6468 - val_accuracy: 0.5000\nEpoch 15/200\n5/5 [==============================] - 3s 504ms/step - loss: 3.5460 - accuracy: 0.7846 - val_loss: 3.6398 - val_accuracy: 0.5714\nEpoch 16/200\n5/5 [==============================] - 3s 508ms/step - loss: 3.3889 - accuracy: 0.8615 - val_loss: 3.6358 - val_accuracy: 0.6429\nEpoch 17/200\n5/5 [==============================] - 3s 507ms/step - loss: 3.5389 - accuracy: 0.8308 - val_loss: 3.6278 - val_accuracy: 0.6429\nEpoch 18/200\n5/5 [==============================] - 3s 513ms/step - loss: 3.5376 - accuracy: 0.8000 - val_loss: 3.6231 - val_accuracy: 0.6429\nEpoch 19/200\n5/5 [==============================] - 3s 520ms/step - loss: 3.4616 - accuracy: 0.7538 - val_loss: 3.6154 - val_accuracy: 0.6429\nEpoch 20/200\n5/5 [==============================] - 3s 510ms/step - loss: 3.5867 - accuracy: 0.6462 - val_loss: 3.6080 - val_accuracy: 0.6429\nEpoch 21/200\n5/5 [==============================] - 3s 511ms/step - loss: 3.6578 - accuracy: 0.7385 - val_loss: 3.5952 - val_accuracy: 0.7143\nEpoch 22/200\n5/5 [==============================] - 3s 506ms/step - loss: 3.6224 - accuracy: 0.6769 - val_loss: 3.5777 - val_accuracy: 0.7857\nEpoch 23/200\n5/5 [==============================] - 3s 512ms/step - loss: 3.5247 - accuracy: 0.7231 - val_loss: 3.5683 - val_accuracy: 0.7857\nEpoch 24/200\n5/5 [==============================] - 3s 517ms/step - loss: 3.4038 - accuracy: 0.8615 - val_loss: 3.5685 - val_accuracy: 0.7857\nEpoch 25/200\n5/5 [==============================] - 3s 500ms/step - loss: 3.4044 - accuracy: 0.7231 - val_loss: 3.5613 - val_accuracy: 0.7857\nEpoch 26/200\n5/5 [==============================] - 3s 515ms/step - loss: 3.4250 - accuracy: 0.7385 - val_loss: 3.5534 - val_accuracy: 0.7857\nEpoch 27/200\n5/5 [==============================] - 3s 508ms/step - loss: 3.2930 - accuracy: 0.8308 - val_loss: 3.5416 - val_accuracy: 0.7857\nEpoch 28/200\n5/5 [==============================] - 3s 507ms/step - loss: 3.3167 - accuracy: 0.8308 - val_loss: 3.5325 - val_accuracy: 0.7857\nEpoch 29/200\n5/5 [==============================] - 3s 508ms/step - loss: 3.4276 - accuracy: 0.7846 - val_loss: 3.5200 - val_accuracy: 0.7857\nEpoch 30/200\n5/5 [==============================] - 3s 514ms/step - loss: 3.2924 - accuracy: 0.8308 - val_loss: 3.5096 - val_accuracy: 0.7857\nEpoch 31/200\n5/5 [==============================] - 3s 515ms/step - loss: 3.4077 - accuracy: 0.7846 - val_loss: 3.4992 - val_accuracy: 0.7857\nEpoch 32/200\n5/5 [==============================] - 3s 512ms/step - loss: 3.2991 - accuracy: 0.8462 - val_loss: 3.4926 - val_accuracy: 0.7857\nEpoch 33/200\n5/5 [==============================] - 3s 511ms/step - loss: 3.2438 - accuracy: 0.9231 - val_loss: 3.4884 - val_accuracy: 0.7857\nEpoch 34/200\n5/5 [==============================] - 3s 514ms/step - loss: 3.2745 - accuracy: 0.8308 - val_loss: 3.4846 - val_accuracy: 0.7857\nEpoch 35/200\n5/5 [==============================] - 3s 512ms/step - loss: 3.4235 - accuracy: 0.8154 - val_loss: 3.4771 - val_accuracy: 0.7857\nEpoch 36/200\n5/5 [==============================] - 3s 505ms/step - loss: 3.3162 - accuracy: 0.8154 - val_loss: 3.4581 - val_accuracy: 0.7857\nEpoch 37/200\n5/5 [==============================] - 3s 513ms/step - loss: 3.2075 - accuracy: 0.8615 - val_loss: 3.4472 - val_accuracy: 0.7857\nEpoch 38/200\n5/5 [==============================] - 3s 522ms/step - loss: 3.1760 - accuracy: 0.9077 - val_loss: 3.4402 - val_accuracy: 0.7857\nEpoch 39/200\n5/5 [==============================] - 3s 518ms/step - loss: 3.2476 - accuracy: 0.8923 - val_loss: 3.4319 - val_accuracy: 0.7857\nEpoch 40/200\n5/5 [==============================] - 3s 519ms/step - loss: 3.2235 - accuracy: 0.8923 - val_loss: 3.4256 - val_accuracy: 0.7857\nEpoch 41/200\n5/5 [==============================] - 3s 513ms/step - loss: 3.1741 - accuracy: 0.8923 - val_loss: 3.4214 - val_accuracy: 0.7857\nEpoch 42/200\n5/5 [==============================] - 3s 517ms/step - loss: 3.1807 - accuracy: 0.9231 - val_loss: 3.4175 - val_accuracy: 0.7857\nEpoch 43/200\n5/5 [==============================] - 3s 547ms/step - loss: 3.1438 - accuracy: 0.9077 - val_loss: 3.4151 - val_accuracy: 0.7857\nEpoch 44/200\n5/5 [==============================] - 3s 514ms/step - loss: 3.1728 - accuracy: 0.8769 - val_loss: 3.4115 - val_accuracy: 0.7857\nEpoch 45/200\n5/5 [==============================] - 3s 515ms/step - loss: 3.1600 - accuracy: 0.8615 - val_loss: 3.4110 - val_accuracy: 0.7857\nEpoch 46/200\n5/5 [==============================] - 3s 515ms/step - loss: 3.0539 - accuracy: 0.9538 - val_loss: 3.4175 - val_accuracy: 0.7857\nEpoch 47/200\n5/5 [==============================] - 3s 522ms/step - loss: 3.1204 - accuracy: 0.9231 - val_loss: 3.4208 - val_accuracy: 0.7857\nEpoch 48/200\n5/5 [==============================] - 3s 517ms/step - loss: 3.0594 - accuracy: 0.9385 - val_loss: 3.4220 - val_accuracy: 0.7857\nEpoch 49/200\n5/5 [==============================] - 3s 526ms/step - loss: 3.1382 - accuracy: 0.8615 - val_loss: 3.4195 - val_accuracy: 0.7857\nEpoch 50/200\n5/5 [==============================] - 3s 525ms/step - loss: 3.1010 - accuracy: 0.8923 - val_loss: 3.4110 - val_accuracy: 0.7857\nEpoch 51/200\n5/5 [==============================] - 3s 519ms/step - loss: 3.1218 - accuracy: 0.8923 - val_loss: 3.3930 - val_accuracy: 0.7857\nEpoch 52/200\n5/5 [==============================] - 3s 522ms/step - loss: 3.0498 - accuracy: 0.9385 - val_loss: 3.3875 - val_accuracy: 0.7857\nEpoch 53/200\n5/5 [==============================] - 3s 522ms/step - loss: 3.0225 - accuracy: 0.9692 - val_loss: 3.3716 - val_accuracy: 0.7857\nEpoch 54/200\n5/5 [==============================] - 3s 519ms/step - loss: 3.1409 - accuracy: 0.9077 - val_loss: 3.3557 - val_accuracy: 0.7857\nEpoch 55/200\n5/5 [==============================] - 3s 561ms/step - loss: 3.1608 - accuracy: 0.8923 - val_loss: 3.3475 - val_accuracy: 0.7857\nEpoch 56/200\n5/5 [==============================] - 3s 517ms/step - loss: 3.1283 - accuracy: 0.8923 - val_loss: 3.3410 - val_accuracy: 0.7857\nEpoch 57/200\n5/5 [==============================] - 3s 521ms/step - loss: 3.0623 - accuracy: 0.9231 - val_loss: 3.3331 - val_accuracy: 0.7857\nEpoch 58/200\n5/5 [==============================] - 3s 519ms/step - loss: 3.0496 - accuracy: 0.9231 - val_loss: 3.3273 - val_accuracy: 0.7857\nEpoch 59/200\n5/5 [==============================] - 3s 518ms/step - loss: 3.1318 - accuracy: 0.8462 - val_loss: 3.3295 - val_accuracy: 0.7857\nEpoch 60/200\n5/5 [==============================] - 3s 529ms/step - loss: 3.0490 - accuracy: 0.8923 - val_loss: 3.3527 - val_accuracy: 0.7857\nEpoch 61/200\n5/5 [==============================] - 3s 518ms/step - loss: 3.0904 - accuracy: 0.9077 - val_loss: 3.3741 - val_accuracy: 0.7857\nEpoch 62/200\n5/5 [==============================] - 3s 522ms/step - loss: 2.9750 - accuracy: 0.9846 - val_loss: 3.3868 - val_accuracy: 0.7143\nEpoch 63/200\n5/5 [==============================] - 3s 528ms/step - loss: 3.0184 - accuracy: 0.9231 - val_loss: 3.3907 - val_accuracy: 0.7143\nEpoch 64/200\n5/5 [==============================] - 3s 528ms/step - loss: 3.0143 - accuracy: 0.9385 - val_loss: 3.3929 - val_accuracy: 0.7143\nEpoch 65/200\n5/5 [==============================] - 3s 522ms/step - loss: 3.0184 - accuracy: 0.9538 - val_loss: 3.3802 - val_accuracy: 0.7143\nEpoch 66/200\n5/5 [==============================] - 3s 524ms/step - loss: 3.0054 - accuracy: 0.9385 - val_loss: 3.3722 - val_accuracy: 0.7143\nEpoch 67/200\n5/5 [==============================] - 3s 544ms/step - loss: 3.0982 - accuracy: 0.8923 - val_loss: 3.3634 - val_accuracy: 0.7143\nEpoch 68/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.9615 - accuracy: 0.9231 - val_loss: 3.3401 - val_accuracy: 0.7857\nEpoch 69/200\n5/5 [==============================] - 3s 520ms/step - loss: 2.9838 - accuracy: 0.9077 - val_loss: 3.3458 - val_accuracy: 0.7143\nEpoch 70/200\n5/5 [==============================] - 3s 531ms/step - loss: 3.0007 - accuracy: 0.9231 - val_loss: 3.3458 - val_accuracy: 0.7143\nEpoch 71/200\n5/5 [==============================] - 3s 519ms/step - loss: 3.0374 - accuracy: 0.9077 - val_loss: 3.3416 - val_accuracy: 0.7143\nEpoch 72/200\n5/5 [==============================] - 3s 531ms/step - loss: 2.9385 - accuracy: 0.9846 - val_loss: 3.3236 - val_accuracy: 0.7143\nEpoch 73/200\n5/5 [==============================] - 3s 516ms/step - loss: 2.9541 - accuracy: 0.9385 - val_loss: 3.3166 - val_accuracy: 0.7143\nEpoch 74/200\n5/5 [==============================] - 3s 530ms/step - loss: 2.9820 - accuracy: 0.9692 - val_loss: 3.3102 - val_accuracy: 0.7143\nEpoch 75/200\n5/5 [==============================] - 3s 534ms/step - loss: 2.9938 - accuracy: 0.9385 - val_loss: 3.3089 - val_accuracy: 0.7143\nEpoch 76/200\n5/5 [==============================] - 3s 534ms/step - loss: 2.9228 - accuracy: 0.9846 - val_loss: 3.3075 - val_accuracy: 0.7143\nEpoch 77/200\n5/5 [==============================] - 3s 520ms/step - loss: 2.9486 - accuracy: 0.9692 - val_loss: 3.3056 - val_accuracy: 0.7143\nEpoch 78/200\n5/5 [==============================] - 3s 547ms/step - loss: 3.0096 - accuracy: 0.9231 - val_loss: 3.3039 - val_accuracy: 0.7143\nEpoch 79/200\n5/5 [==============================] - 3s 620ms/step - loss: 2.9675 - accuracy: 0.9385 - val_loss: 3.3034 - val_accuracy: 0.7143\nEpoch 80/200\n5/5 [==============================] - 6s 1s/step - loss: 2.9703 - accuracy: 0.8923 - val_loss: 3.3077 - val_accuracy: 0.7143\nEpoch 81/200\n5/5 [==============================] - 4s 832ms/step - loss: 2.9369 - accuracy: 0.9385 - val_loss: 3.3075 - val_accuracy: 0.7143\nEpoch 82/200\n5/5 [==============================] - 5s 910ms/step - loss: 2.8914 - accuracy: 0.9846 - val_loss: 3.3065 - val_accuracy: 0.7143\nEpoch 83/200\n5/5 [==============================] - 4s 868ms/step - loss: 2.8776 - accuracy: 0.9846 - val_loss: 3.3064 - val_accuracy: 0.7143\nEpoch 84/200\n5/5 [==============================] - 3s 593ms/step - loss: 2.8975 - accuracy: 0.9538 - val_loss: 3.3156 - val_accuracy: 0.7143\nEpoch 85/200\n5/5 [==============================] - 3s 532ms/step - loss: 2.8854 - accuracy: 0.9538 - val_loss: 3.3150 - val_accuracy: 0.7143\nEpoch 86/200\n5/5 [==============================] - 3s 537ms/step - loss: 2.8560 - accuracy: 0.9846 - val_loss: 3.2910 - val_accuracy: 0.7143\nEpoch 87/200\n5/5 [==============================] - 3s 529ms/step - loss: 2.9106 - accuracy: 0.9538 - val_loss: 3.2920 - val_accuracy: 0.7143\nEpoch 88/200\n5/5 [==============================] - 3s 523ms/step - loss: 2.8839 - accuracy: 0.9846 - val_loss: 3.2966 - val_accuracy: 0.7143\nEpoch 89/200\n5/5 [==============================] - 3s 539ms/step - loss: 2.8679 - accuracy: 0.9692 - val_loss: 3.2962 - val_accuracy: 0.7143\nEpoch 90/200\n5/5 [==============================] - 3s 524ms/step - loss: 2.8830 - accuracy: 0.9692 - val_loss: 3.2959 - val_accuracy: 0.7143\nEpoch 91/200\n5/5 [==============================] - 3s 527ms/step - loss: 2.8807 - accuracy: 0.9846 - val_loss: 3.2966 - val_accuracy: 0.7143\nEpoch 92/200\n5/5 [==============================] - 3s 519ms/step - loss: 2.8298 - accuracy: 1.0000 - val_loss: 3.2973 - val_accuracy: 0.7143\nEpoch 93/200\n5/5 [==============================] - 3s 523ms/step - loss: 2.8918 - accuracy: 0.9538 - val_loss: 3.2944 - val_accuracy: 0.7143\nEpoch 94/200\n5/5 [==============================] - 3s 524ms/step - loss: 2.8322 - accuracy: 0.9692 - val_loss: 3.2966 - val_accuracy: 0.7143\nEpoch 95/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.9939 - accuracy: 0.9538 - val_loss: 3.3119 - val_accuracy: 0.7143\nEpoch 96/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.8659 - accuracy: 0.9846 - val_loss: 3.3646 - val_accuracy: 0.7143\nEpoch 97/200\n5/5 [==============================] - 3s 521ms/step - loss: 2.8793 - accuracy: 0.9692 - val_loss: 3.3916 - val_accuracy: 0.7143\nEpoch 98/200\n5/5 [==============================] - 3s 571ms/step - loss: 2.8454 - accuracy: 0.9846 - val_loss: 3.4066 - val_accuracy: 0.7143\nEpoch 99/200\n5/5 [==============================] - 3s 524ms/step - loss: 2.8385 - accuracy: 0.9846 - val_loss: 3.4123 - val_accuracy: 0.7143\nEpoch 100/200\n5/5 [==============================] - 3s 515ms/step - loss: 2.8575 - accuracy: 0.9385 - val_loss: 3.4153 - val_accuracy: 0.7143\nEpoch 101/200\n5/5 [==============================] - 3s 530ms/step - loss: 2.8655 - accuracy: 0.9538 - val_loss: 3.4227 - val_accuracy: 0.7143\nEpoch 102/200\n5/5 [==============================] - 3s 533ms/step - loss: 2.8660 - accuracy: 0.9692 - val_loss: 3.4244 - val_accuracy: 0.7143\nEpoch 103/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.8061 - accuracy: 0.9846 - val_loss: 3.4189 - val_accuracy: 0.7143\nEpoch 104/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.7908 - accuracy: 0.9846 - val_loss: 3.4177 - val_accuracy: 0.7143\nEpoch 105/200\n5/5 [==============================] - 3s 531ms/step - loss: 2.8433 - accuracy: 0.9385 - val_loss: 3.4045 - val_accuracy: 0.7143\nEpoch 106/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.7851 - accuracy: 0.9692 - val_loss: 3.4060 - val_accuracy: 0.7143\n3/3 [==============================] - 1s 161ms/step - loss: 2.9245 - accuracy: 1.0000\n1/1 [==============================] - 0s 285ms/step - loss: 3.2910 - accuracy: 0.7143\n1/1 [==============================] - 0s 356ms/step\nEpoch 1/200\n5/5 [==============================] - 3s 563ms/step - loss: 3.1070 - accuracy: 0.8939 - val_loss: 2.9198 - val_accuracy: 1.0000\nEpoch 2/200\n5/5 [==============================] - 2s 485ms/step - loss: 3.3253 - accuracy: 0.8485 - val_loss: 2.9019 - val_accuracy: 1.0000\nEpoch 3/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.8859 - accuracy: 0.9697 - val_loss: 2.8920 - val_accuracy: 1.0000\nEpoch 4/200\n5/5 [==============================] - 2s 473ms/step - loss: 2.9321 - accuracy: 0.9091 - val_loss: 2.8856 - val_accuracy: 1.0000\nEpoch 5/200\n5/5 [==============================] - 2s 480ms/step - loss: 2.9161 - accuracy: 0.9545 - val_loss: 2.8818 - val_accuracy: 1.0000\nEpoch 6/200\n5/5 [==============================] - 2s 491ms/step - loss: 3.0883 - accuracy: 0.9091 - val_loss: 2.8779 - val_accuracy: 1.0000\nEpoch 7/200\n5/5 [==============================] - 2s 487ms/step - loss: 3.2044 - accuracy: 0.9091 - val_loss: 2.8694 - val_accuracy: 1.0000\nEpoch 8/200\n5/5 [==============================] - 2s 482ms/step - loss: 2.8709 - accuracy: 0.9545 - val_loss: 2.8614 - val_accuracy: 1.0000\nEpoch 9/200\n5/5 [==============================] - 2s 488ms/step - loss: 2.9104 - accuracy: 0.9091 - val_loss: 2.8544 - val_accuracy: 1.0000\nEpoch 10/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.9979 - accuracy: 0.9242 - val_loss: 2.8474 - val_accuracy: 1.0000\nEpoch 11/200\n5/5 [==============================] - 2s 491ms/step - loss: 2.8902 - accuracy: 0.9394 - val_loss: 2.8390 - val_accuracy: 1.0000\nEpoch 12/200\n5/5 [==============================] - 2s 488ms/step - loss: 2.8434 - accuracy: 0.9545 - val_loss: 2.8363 - val_accuracy: 1.0000\nEpoch 13/200\n5/5 [==============================] - 2s 489ms/step - loss: 2.8097 - accuracy: 0.9848 - val_loss: 2.8308 - val_accuracy: 1.0000\nEpoch 14/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.8423 - accuracy: 0.9545 - val_loss: 2.8244 - val_accuracy: 1.0000\nEpoch 15/200\n5/5 [==============================] - 2s 490ms/step - loss: 2.8849 - accuracy: 0.9545 - val_loss: 2.8178 - val_accuracy: 1.0000\nEpoch 16/200\n5/5 [==============================] - 2s 497ms/step - loss: 2.8362 - accuracy: 0.9545 - val_loss: 2.8132 - val_accuracy: 1.0000\nEpoch 17/200\n5/5 [==============================] - 2s 492ms/step - loss: 2.8295 - accuracy: 0.9697 - val_loss: 2.8110 - val_accuracy: 1.0000\nEpoch 18/200\n5/5 [==============================] - 2s 487ms/step - loss: 2.7919 - accuracy: 0.9848 - val_loss: 2.8088 - val_accuracy: 1.0000\nEpoch 19/200\n5/5 [==============================] - 2s 490ms/step - loss: 2.7445 - accuracy: 1.0000 - val_loss: 2.8071 - val_accuracy: 1.0000\nEpoch 20/200\n5/5 [==============================] - 2s 479ms/step - loss: 2.8209 - accuracy: 0.9242 - val_loss: 2.8017 - val_accuracy: 1.0000\nEpoch 21/200\n5/5 [==============================] - 2s 486ms/step - loss: 2.8257 - accuracy: 0.9545 - val_loss: 2.7927 - val_accuracy: 1.0000\nEpoch 22/200\n5/5 [==============================] - 2s 482ms/step - loss: 2.8178 - accuracy: 0.9545 - val_loss: 2.7870 - val_accuracy: 1.0000\nEpoch 23/200\n5/5 [==============================] - 2s 496ms/step - loss: 2.7832 - accuracy: 0.9697 - val_loss: 2.7826 - val_accuracy: 1.0000\nEpoch 24/200\n5/5 [==============================] - 2s 494ms/step - loss: 2.8091 - accuracy: 0.9545 - val_loss: 2.7817 - val_accuracy: 1.0000\nEpoch 25/200\n5/5 [==============================] - 2s 491ms/step - loss: 2.7638 - accuracy: 0.9545 - val_loss: 2.7776 - val_accuracy: 1.0000\nEpoch 26/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.7524 - accuracy: 0.9848 - val_loss: 2.7723 - val_accuracy: 1.0000\nEpoch 27/200\n5/5 [==============================] - 2s 497ms/step - loss: 2.7408 - accuracy: 1.0000 - val_loss: 2.7669 - val_accuracy: 1.0000\nEpoch 28/200\n5/5 [==============================] - 2s 493ms/step - loss: 2.7241 - accuracy: 1.0000 - val_loss: 2.7631 - val_accuracy: 1.0000\nEpoch 29/200\n5/5 [==============================] - 2s 491ms/step - loss: 2.7710 - accuracy: 0.9697 - val_loss: 2.7628 - val_accuracy: 1.0000\nEpoch 30/200\n5/5 [==============================] - 2s 496ms/step - loss: 2.7499 - accuracy: 0.9848 - val_loss: 2.7693 - val_accuracy: 1.0000\nEpoch 31/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.7209 - accuracy: 0.9848 - val_loss: 2.7689 - val_accuracy: 1.0000\nEpoch 32/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.7589 - accuracy: 0.9697 - val_loss: 2.7650 - val_accuracy: 1.0000\nEpoch 33/200\n5/5 [==============================] - 3s 496ms/step - loss: 2.7810 - accuracy: 0.9848 - val_loss: 2.7628 - val_accuracy: 1.0000\nEpoch 34/200\n5/5 [==============================] - 2s 490ms/step - loss: 2.7577 - accuracy: 0.9545 - val_loss: 2.7541 - val_accuracy: 1.0000\nEpoch 35/200\n5/5 [==============================] - 2s 487ms/step - loss: 2.7337 - accuracy: 0.9697 - val_loss: 2.7462 - val_accuracy: 1.0000\nEpoch 36/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.7077 - accuracy: 0.9848 - val_loss: 2.7394 - val_accuracy: 1.0000\nEpoch 37/200\n5/5 [==============================] - 3s 498ms/step - loss: 2.7158 - accuracy: 0.9848 - val_loss: 2.7314 - val_accuracy: 1.0000\nEpoch 38/200\n5/5 [==============================] - 2s 490ms/step - loss: 2.7113 - accuracy: 0.9848 - val_loss: 2.7277 - val_accuracy: 1.0000\nEpoch 39/200\n5/5 [==============================] - 3s 503ms/step - loss: 2.6980 - accuracy: 1.0000 - val_loss: 2.7256 - val_accuracy: 1.0000\nEpoch 40/200\n5/5 [==============================] - 2s 494ms/step - loss: 2.6883 - accuracy: 0.9848 - val_loss: 2.7233 - val_accuracy: 1.0000\nEpoch 41/200\n5/5 [==============================] - 2s 505ms/step - loss: 2.7072 - accuracy: 0.9848 - val_loss: 2.7201 - val_accuracy: 1.0000\nEpoch 42/200\n5/5 [==============================] - 2s 493ms/step - loss: 2.7246 - accuracy: 0.9848 - val_loss: 2.7102 - val_accuracy: 1.0000\nEpoch 43/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.6928 - accuracy: 0.9848 - val_loss: 2.7017 - val_accuracy: 1.0000\nEpoch 44/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.6579 - accuracy: 1.0000 - val_loss: 2.6965 - val_accuracy: 1.0000\nEpoch 45/200\n5/5 [==============================] - 2s 494ms/step - loss: 2.7185 - accuracy: 0.9697 - val_loss: 2.6895 - val_accuracy: 1.0000\nEpoch 46/200\n5/5 [==============================] - 2s 496ms/step - loss: 2.6745 - accuracy: 0.9848 - val_loss: 2.6827 - val_accuracy: 1.0000\nEpoch 47/200\n5/5 [==============================] - 2s 496ms/step - loss: 2.6608 - accuracy: 1.0000 - val_loss: 2.6775 - val_accuracy: 1.0000\nEpoch 48/200\n5/5 [==============================] - 2s 487ms/step - loss: 2.6673 - accuracy: 1.0000 - val_loss: 2.6733 - val_accuracy: 1.0000\nEpoch 49/200\n5/5 [==============================] - 2s 494ms/step - loss: 2.6663 - accuracy: 0.9848 - val_loss: 2.6698 - val_accuracy: 1.0000\nEpoch 50/200\n5/5 [==============================] - 2s 501ms/step - loss: 2.6584 - accuracy: 1.0000 - val_loss: 2.6675 - val_accuracy: 1.0000\nEpoch 51/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.6913 - accuracy: 0.9848 - val_loss: 2.6657 - val_accuracy: 1.0000\nEpoch 52/200\n5/5 [==============================] - 2s 486ms/step - loss: 2.6973 - accuracy: 0.9848 - val_loss: 2.6631 - val_accuracy: 1.0000\nEpoch 53/200\n5/5 [==============================] - 2s 490ms/step - loss: 2.6601 - accuracy: 1.0000 - val_loss: 2.6592 - val_accuracy: 1.0000\nEpoch 54/200\n5/5 [==============================] - 2s 488ms/step - loss: 2.7017 - accuracy: 0.9697 - val_loss: 2.6543 - val_accuracy: 1.0000\nEpoch 55/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.6190 - accuracy: 1.0000 - val_loss: 2.6493 - val_accuracy: 1.0000\nEpoch 56/200\n5/5 [==============================] - 2s 488ms/step - loss: 2.6407 - accuracy: 1.0000 - val_loss: 2.6448 - val_accuracy: 1.0000\nEpoch 57/200\n5/5 [==============================] - 2s 491ms/step - loss: 2.6314 - accuracy: 1.0000 - val_loss: 2.6406 - val_accuracy: 1.0000\nEpoch 58/200\n5/5 [==============================] - 3s 502ms/step - loss: 2.6641 - accuracy: 0.9848 - val_loss: 2.6349 - val_accuracy: 1.0000\nEpoch 59/200\n5/5 [==============================] - 2s 502ms/step - loss: 2.6333 - accuracy: 0.9848 - val_loss: 2.6290 - val_accuracy: 1.0000\nEpoch 60/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.6112 - accuracy: 1.0000 - val_loss: 2.6251 - val_accuracy: 1.0000\nEpoch 61/200\n5/5 [==============================] - 2s 488ms/step - loss: 2.6267 - accuracy: 1.0000 - val_loss: 2.6220 - val_accuracy: 1.0000\nEpoch 62/200\n5/5 [==============================] - 3s 504ms/step - loss: 2.6070 - accuracy: 1.0000 - val_loss: 2.6193 - val_accuracy: 1.0000\nEpoch 63/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.6129 - accuracy: 1.0000 - val_loss: 2.6172 - val_accuracy: 1.0000\nEpoch 64/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.6012 - accuracy: 1.0000 - val_loss: 2.6153 - val_accuracy: 1.0000\nEpoch 65/200\n5/5 [==============================] - 2s 485ms/step - loss: 2.6961 - accuracy: 0.9848 - val_loss: 2.6111 - val_accuracy: 1.0000\nEpoch 66/200\n5/5 [==============================] - 3s 500ms/step - loss: 2.6016 - accuracy: 0.9848 - val_loss: 2.6068 - val_accuracy: 1.0000\nEpoch 67/200\n5/5 [==============================] - 2s 501ms/step - loss: 2.5863 - accuracy: 1.0000 - val_loss: 2.6031 - val_accuracy: 1.0000\nEpoch 68/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.6082 - accuracy: 0.9848 - val_loss: 2.6002 - val_accuracy: 1.0000\nEpoch 69/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.6216 - accuracy: 0.9848 - val_loss: 2.5986 - val_accuracy: 1.0000\nEpoch 70/200\n5/5 [==============================] - 2s 494ms/step - loss: 2.5803 - accuracy: 1.0000 - val_loss: 2.5966 - val_accuracy: 1.0000\nEpoch 71/200\n5/5 [==============================] - 3s 502ms/step - loss: 2.6055 - accuracy: 0.9848 - val_loss: 2.5946 - val_accuracy: 1.0000\nEpoch 72/200\n5/5 [==============================] - 3s 502ms/step - loss: 2.5751 - accuracy: 1.0000 - val_loss: 2.5922 - val_accuracy: 1.0000\nEpoch 73/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.5848 - accuracy: 1.0000 - val_loss: 2.5899 - val_accuracy: 1.0000\nEpoch 74/200\n5/5 [==============================] - 3s 501ms/step - loss: 2.5904 - accuracy: 0.9848 - val_loss: 2.5874 - val_accuracy: 1.0000\nEpoch 75/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.5849 - accuracy: 0.9848 - val_loss: 2.5859 - val_accuracy: 1.0000\nEpoch 76/200\n5/5 [==============================] - 3s 522ms/step - loss: 2.5717 - accuracy: 1.0000 - val_loss: 2.5846 - val_accuracy: 1.0000\nEpoch 77/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.5605 - accuracy: 1.0000 - val_loss: 2.5837 - val_accuracy: 1.0000\nEpoch 78/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.5576 - accuracy: 1.0000 - val_loss: 2.5813 - val_accuracy: 1.0000\nEpoch 79/200\n5/5 [==============================] - 3s 505ms/step - loss: 2.5633 - accuracy: 1.0000 - val_loss: 2.5788 - val_accuracy: 1.0000\nEpoch 80/200\n5/5 [==============================] - 2s 495ms/step - loss: 2.5703 - accuracy: 0.9848 - val_loss: 2.5756 - val_accuracy: 1.0000\nEpoch 81/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.5509 - accuracy: 0.9848 - val_loss: 2.5733 - val_accuracy: 1.0000\nEpoch 82/200\n5/5 [==============================] - 2s 498ms/step - loss: 2.5641 - accuracy: 0.9848 - val_loss: 2.5699 - val_accuracy: 1.0000\nEpoch 83/200\n5/5 [==============================] - 2s 493ms/step - loss: 2.5546 - accuracy: 0.9848 - val_loss: 2.5659 - val_accuracy: 1.0000\nEpoch 84/200\n5/5 [==============================] - 3s 500ms/step - loss: 2.5797 - accuracy: 0.9848 - val_loss: 2.5645 - val_accuracy: 1.0000\nEpoch 85/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.5457 - accuracy: 1.0000 - val_loss: 2.5612 - val_accuracy: 1.0000\nEpoch 86/200\n5/5 [==============================] - 2s 493ms/step - loss: 2.5501 - accuracy: 1.0000 - val_loss: 2.5587 - val_accuracy: 1.0000\nEpoch 87/200\n5/5 [==============================] - 3s 504ms/step - loss: 2.5311 - accuracy: 1.0000 - val_loss: 2.5565 - val_accuracy: 1.0000\nEpoch 88/200\n5/5 [==============================] - 3s 541ms/step - loss: 2.5344 - accuracy: 1.0000 - val_loss: 2.5555 - val_accuracy: 1.0000\nEpoch 89/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.5583 - accuracy: 0.9697 - val_loss: 2.5550 - val_accuracy: 1.0000\nEpoch 90/200\n5/5 [==============================] - 2s 493ms/step - loss: 2.5154 - accuracy: 1.0000 - val_loss: 2.5546 - val_accuracy: 1.0000\nEpoch 91/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.5193 - accuracy: 1.0000 - val_loss: 2.5533 - val_accuracy: 1.0000\nEpoch 92/200\n5/5 [==============================] - 2s 502ms/step - loss: 2.5266 - accuracy: 1.0000 - val_loss: 2.5508 - val_accuracy: 1.0000\nEpoch 93/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.5069 - accuracy: 1.0000 - val_loss: 2.5481 - val_accuracy: 1.0000\nEpoch 94/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.5123 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 1.0000\nEpoch 95/200\n5/5 [==============================] - 3s 496ms/step - loss: 2.5131 - accuracy: 1.0000 - val_loss: 2.5370 - val_accuracy: 1.0000\nEpoch 96/200\n5/5 [==============================] - 3s 504ms/step - loss: 2.5109 - accuracy: 1.0000 - val_loss: 2.5333 - val_accuracy: 1.0000\nEpoch 97/200\n5/5 [==============================] - 3s 502ms/step - loss: 2.5130 - accuracy: 1.0000 - val_loss: 2.5286 - val_accuracy: 1.0000\nEpoch 98/200\n5/5 [==============================] - 2s 502ms/step - loss: 2.4943 - accuracy: 1.0000 - val_loss: 2.5251 - val_accuracy: 1.0000\nEpoch 99/200\n5/5 [==============================] - 2s 500ms/step - loss: 2.4867 - accuracy: 1.0000 - val_loss: 2.5221 - val_accuracy: 1.0000\nEpoch 100/200\n5/5 [==============================] - 3s 545ms/step - loss: 2.4913 - accuracy: 1.0000 - val_loss: 2.5189 - val_accuracy: 1.0000\nEpoch 101/200\n5/5 [==============================] - 2s 491ms/step - loss: 2.5010 - accuracy: 0.9848 - val_loss: 2.5149 - val_accuracy: 1.0000\nEpoch 102/200\n5/5 [==============================] - 2s 496ms/step - loss: 2.4964 - accuracy: 1.0000 - val_loss: 2.5104 - val_accuracy: 1.0000\nEpoch 103/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.4827 - accuracy: 1.0000 - val_loss: 2.5064 - val_accuracy: 1.0000\nEpoch 104/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.4850 - accuracy: 1.0000 - val_loss: 2.5042 - val_accuracy: 1.0000\nEpoch 105/200\n5/5 [==============================] - 3s 500ms/step - loss: 2.4707 - accuracy: 1.0000 - val_loss: 2.5019 - val_accuracy: 1.0000\nEpoch 106/200\n5/5 [==============================] - 3s 503ms/step - loss: 2.4831 - accuracy: 1.0000 - val_loss: 2.5004 - val_accuracy: 1.0000\nEpoch 107/200\n5/5 [==============================] - 3s 525ms/step - loss: 2.4776 - accuracy: 1.0000 - val_loss: 2.4980 - val_accuracy: 1.0000\nEpoch 108/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.4840 - accuracy: 0.9848 - val_loss: 2.4958 - val_accuracy: 1.0000\nEpoch 109/200\n5/5 [==============================] - 3s 503ms/step - loss: 2.4592 - accuracy: 1.0000 - val_loss: 2.4909 - val_accuracy: 1.0000\nEpoch 110/200\n5/5 [==============================] - 3s 504ms/step - loss: 2.4760 - accuracy: 1.0000 - val_loss: 2.4878 - val_accuracy: 1.0000\nEpoch 111/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.4951 - accuracy: 0.9697 - val_loss: 2.4875 - val_accuracy: 1.0000\nEpoch 112/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.4555 - accuracy: 1.0000 - val_loss: 2.4845 - val_accuracy: 1.0000\nEpoch 113/200\n5/5 [==============================] - 2s 498ms/step - loss: 2.4516 - accuracy: 1.0000 - val_loss: 2.4817 - val_accuracy: 1.0000\nEpoch 114/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.4647 - accuracy: 0.9848 - val_loss: 2.4799 - val_accuracy: 1.0000\nEpoch 115/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.4453 - accuracy: 1.0000 - val_loss: 2.4785 - val_accuracy: 1.0000\nEpoch 116/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.4490 - accuracy: 1.0000 - val_loss: 2.4759 - val_accuracy: 1.0000\nEpoch 117/200\n5/5 [==============================] - 2s 499ms/step - loss: 2.4459 - accuracy: 1.0000 - val_loss: 2.4732 - val_accuracy: 1.0000\nEpoch 118/200\n5/5 [==============================] - 3s 504ms/step - loss: 2.4404 - accuracy: 1.0000 - val_loss: 2.4703 - val_accuracy: 1.0000\nEpoch 119/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.4342 - accuracy: 1.0000 - val_loss: 2.4669 - val_accuracy: 1.0000\nEpoch 120/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.4258 - accuracy: 1.0000 - val_loss: 2.4638 - val_accuracy: 1.0000\nEpoch 121/200\n5/5 [==============================] - 3s 519ms/step - loss: 2.4389 - accuracy: 1.0000 - val_loss: 2.4604 - val_accuracy: 1.0000\nEpoch 122/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.4300 - accuracy: 1.0000 - val_loss: 2.4570 - val_accuracy: 1.0000\nEpoch 123/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.4180 - accuracy: 1.0000 - val_loss: 2.4536 - val_accuracy: 1.0000\nEpoch 124/200\n5/5 [==============================] - 3s 538ms/step - loss: 2.4268 - accuracy: 1.0000 - val_loss: 2.4509 - val_accuracy: 1.0000\nEpoch 125/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.4240 - accuracy: 1.0000 - val_loss: 2.4483 - val_accuracy: 1.0000\nEpoch 126/200\n5/5 [==============================] - 3s 516ms/step - loss: 2.4224 - accuracy: 1.0000 - val_loss: 2.4483 - val_accuracy: 1.0000\nEpoch 127/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.4066 - accuracy: 1.0000 - val_loss: 2.4455 - val_accuracy: 1.0000\nEpoch 128/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.4076 - accuracy: 1.0000 - val_loss: 2.4418 - val_accuracy: 1.0000\nEpoch 129/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.4020 - accuracy: 1.0000 - val_loss: 2.4386 - val_accuracy: 1.0000\nEpoch 130/200\n5/5 [==============================] - 3s 494ms/step - loss: 2.4133 - accuracy: 1.0000 - val_loss: 2.4353 - val_accuracy: 1.0000\nEpoch 131/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.4060 - accuracy: 1.0000 - val_loss: 2.4318 - val_accuracy: 1.0000\nEpoch 132/200\n5/5 [==============================] - 3s 497ms/step - loss: 2.4059 - accuracy: 1.0000 - val_loss: 2.4284 - val_accuracy: 1.0000\nEpoch 133/200\n5/5 [==============================] - 3s 497ms/step - loss: 2.4056 - accuracy: 1.0000 - val_loss: 2.4255 - val_accuracy: 1.0000\nEpoch 134/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.3910 - accuracy: 1.0000 - val_loss: 2.4224 - val_accuracy: 1.0000\nEpoch 135/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.3939 - accuracy: 1.0000 - val_loss: 2.4189 - val_accuracy: 1.0000\nEpoch 136/200\n5/5 [==============================] - 3s 524ms/step - loss: 2.3949 - accuracy: 0.9848 - val_loss: 2.4167 - val_accuracy: 1.0000\nEpoch 137/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.3846 - accuracy: 1.0000 - val_loss: 2.4259 - val_accuracy: 1.0000\nEpoch 138/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.3859 - accuracy: 1.0000 - val_loss: 2.4304 - val_accuracy: 1.0000\nEpoch 139/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.4061 - accuracy: 0.9848 - val_loss: 2.4315 - val_accuracy: 1.0000\nEpoch 140/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.3773 - accuracy: 1.0000 - val_loss: 2.4246 - val_accuracy: 1.0000\nEpoch 141/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.3683 - accuracy: 1.0000 - val_loss: 2.4187 - val_accuracy: 1.0000\nEpoch 142/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.3721 - accuracy: 1.0000 - val_loss: 2.4157 - val_accuracy: 1.0000\nEpoch 143/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.3705 - accuracy: 1.0000 - val_loss: 2.4135 - val_accuracy: 1.0000\nEpoch 144/200\n5/5 [==============================] - 3s 502ms/step - loss: 2.3732 - accuracy: 1.0000 - val_loss: 2.4106 - val_accuracy: 1.0000\nEpoch 145/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.3725 - accuracy: 1.0000 - val_loss: 2.4080 - val_accuracy: 1.0000\nEpoch 146/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.3943 - accuracy: 0.9848 - val_loss: 2.4068 - val_accuracy: 1.0000\nEpoch 147/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.3541 - accuracy: 1.0000 - val_loss: 2.4055 - val_accuracy: 1.0000\nEpoch 148/200\n5/5 [==============================] - 3s 524ms/step - loss: 2.3644 - accuracy: 1.0000 - val_loss: 2.4028 - val_accuracy: 1.0000\nEpoch 149/200\n5/5 [==============================] - 3s 519ms/step - loss: 2.3771 - accuracy: 0.9697 - val_loss: 2.3947 - val_accuracy: 1.0000\nEpoch 150/200\n5/5 [==============================] - 3s 515ms/step - loss: 2.3509 - accuracy: 1.0000 - val_loss: 2.3900 - val_accuracy: 1.0000\nEpoch 151/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.4041 - accuracy: 0.9697 - val_loss: 2.3853 - val_accuracy: 1.0000\nEpoch 152/200\n5/5 [==============================] - 2s 502ms/step - loss: 2.3416 - accuracy: 1.0000 - val_loss: 2.3819 - val_accuracy: 1.0000\nEpoch 153/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.3593 - accuracy: 0.9848 - val_loss: 2.3795 - val_accuracy: 1.0000\nEpoch 154/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.3313 - accuracy: 1.0000 - val_loss: 2.3775 - val_accuracy: 1.0000\nEpoch 155/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.3415 - accuracy: 1.0000 - val_loss: 2.3753 - val_accuracy: 1.0000\nEpoch 156/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.3264 - accuracy: 1.0000 - val_loss: 2.3728 - val_accuracy: 1.0000\nEpoch 157/200\n5/5 [==============================] - 3s 515ms/step - loss: 2.3419 - accuracy: 1.0000 - val_loss: 2.3722 - val_accuracy: 1.0000\nEpoch 158/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.3302 - accuracy: 1.0000 - val_loss: 2.3709 - val_accuracy: 1.0000\nEpoch 159/200\n5/5 [==============================] - 3s 519ms/step - loss: 2.3361 - accuracy: 1.0000 - val_loss: 2.3689 - val_accuracy: 1.0000\nEpoch 160/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.3186 - accuracy: 1.0000 - val_loss: 2.3669 - val_accuracy: 1.0000\nEpoch 161/200\n5/5 [==============================] - 3s 530ms/step - loss: 2.3268 - accuracy: 1.0000 - val_loss: 2.3648 - val_accuracy: 1.0000\nEpoch 162/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.3155 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 1.0000\nEpoch 163/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.3143 - accuracy: 1.0000 - val_loss: 2.3619 - val_accuracy: 1.0000\nEpoch 164/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.3125 - accuracy: 1.0000 - val_loss: 2.3584 - val_accuracy: 1.0000\nEpoch 165/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.3236 - accuracy: 0.9848 - val_loss: 2.3559 - val_accuracy: 1.0000\nEpoch 166/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.3064 - accuracy: 1.0000 - val_loss: 2.3532 - val_accuracy: 1.0000\nEpoch 167/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.2981 - accuracy: 1.0000 - val_loss: 2.3542 - val_accuracy: 1.0000\nEpoch 168/200\n5/5 [==============================] - 3s 515ms/step - loss: 2.3006 - accuracy: 1.0000 - val_loss: 2.3557 - val_accuracy: 1.0000\nEpoch 169/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.2960 - accuracy: 1.0000 - val_loss: 2.3549 - val_accuracy: 1.0000\nEpoch 170/200\n5/5 [==============================] - 3s 516ms/step - loss: 2.2980 - accuracy: 1.0000 - val_loss: 2.3515 - val_accuracy: 1.0000\nEpoch 171/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.3045 - accuracy: 1.0000 - val_loss: 2.3481 - val_accuracy: 1.0000\nEpoch 172/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.2898 - accuracy: 1.0000 - val_loss: 2.3448 - val_accuracy: 1.0000\nEpoch 173/200\n5/5 [==============================] - 3s 537ms/step - loss: 2.2896 - accuracy: 1.0000 - val_loss: 2.3404 - val_accuracy: 1.0000\nEpoch 174/200\n5/5 [==============================] - 3s 504ms/step - loss: 2.2825 - accuracy: 1.0000 - val_loss: 2.3369 - val_accuracy: 1.0000\nEpoch 175/200\n5/5 [==============================] - 3s 525ms/step - loss: 2.2750 - accuracy: 1.0000 - val_loss: 2.3333 - val_accuracy: 1.0000\nEpoch 176/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.2770 - accuracy: 1.0000 - val_loss: 2.3303 - val_accuracy: 1.0000\nEpoch 177/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.3372 - accuracy: 0.9848 - val_loss: 2.3226 - val_accuracy: 1.0000\nEpoch 178/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.2885 - accuracy: 1.0000 - val_loss: 2.3168 - val_accuracy: 1.0000\nEpoch 179/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.2690 - accuracy: 1.0000 - val_loss: 2.3121 - val_accuracy: 1.0000\nEpoch 180/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.2776 - accuracy: 1.0000 - val_loss: 2.3080 - val_accuracy: 1.0000\nEpoch 181/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.2600 - accuracy: 1.0000 - val_loss: 2.3047 - val_accuracy: 1.0000\nEpoch 182/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.2666 - accuracy: 1.0000 - val_loss: 2.3019 - val_accuracy: 1.0000\nEpoch 183/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.2576 - accuracy: 1.0000 - val_loss: 2.2989 - val_accuracy: 1.0000\nEpoch 184/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.2607 - accuracy: 1.0000 - val_loss: 2.2967 - val_accuracy: 1.0000\nEpoch 185/200\n5/5 [==============================] - 3s 516ms/step - loss: 2.2520 - accuracy: 1.0000 - val_loss: 2.2942 - val_accuracy: 1.0000\nEpoch 186/200\n5/5 [==============================] - 3s 506ms/step - loss: 2.2485 - accuracy: 1.0000 - val_loss: 2.2910 - val_accuracy: 1.0000\nEpoch 187/200\n5/5 [==============================] - 3s 522ms/step - loss: 2.2452 - accuracy: 1.0000 - val_loss: 2.2891 - val_accuracy: 1.0000\nEpoch 188/200\n5/5 [==============================] - 3s 523ms/step - loss: 2.2571 - accuracy: 0.9848 - val_loss: 2.2882 - val_accuracy: 1.0000\nEpoch 189/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.2452 - accuracy: 1.0000 - val_loss: 2.2883 - val_accuracy: 1.0000\nEpoch 190/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.2333 - accuracy: 1.0000 - val_loss: 2.2966 - val_accuracy: 1.0000\nEpoch 191/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.2272 - accuracy: 1.0000 - val_loss: 2.3036 - val_accuracy: 1.0000\nEpoch 192/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.2288 - accuracy: 1.0000 - val_loss: 2.3081 - val_accuracy: 0.9231\nEpoch 193/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.2290 - accuracy: 1.0000 - val_loss: 2.3094 - val_accuracy: 0.9231\nEpoch 194/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.2242 - accuracy: 1.0000 - val_loss: 2.3098 - val_accuracy: 0.9231\nEpoch 195/200\n5/5 [==============================] - 3s 520ms/step - loss: 2.2569 - accuracy: 0.9848 - val_loss: 2.3030 - val_accuracy: 0.9231\nEpoch 196/200\n5/5 [==============================] - 3s 528ms/step - loss: 2.2165 - accuracy: 1.0000 - val_loss: 2.2847 - val_accuracy: 1.0000\nEpoch 197/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.2249 - accuracy: 1.0000 - val_loss: 2.2761 - val_accuracy: 1.0000\nEpoch 198/200\n5/5 [==============================] - 3s 520ms/step - loss: 2.2345 - accuracy: 0.9848 - val_loss: 2.2700 - val_accuracy: 1.0000\nEpoch 199/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.2309 - accuracy: 1.0000 - val_loss: 2.2703 - val_accuracy: 1.0000\nEpoch 200/200\n5/5 [==============================] - 2s 496ms/step - loss: 2.2460 - accuracy: 0.9848 - val_loss: 2.2646 - val_accuracy: 1.0000\n3/3 [==============================] - 1s 148ms/step - loss: 2.1983 - accuracy: 1.0000\n1/1 [==============================] - 0s 239ms/step - loss: 2.2646 - accuracy: 1.0000\n1/1 [==============================] - 0s 280ms/step\nEpoch 1/200\n5/5 [==============================] - 3s 541ms/step - loss: 2.3346 - accuracy: 0.9697 - val_loss: 2.1958 - val_accuracy: 1.0000\nEpoch 2/200\n5/5 [==============================] - 2s 488ms/step - loss: 2.3647 - accuracy: 0.9394 - val_loss: 2.1940 - val_accuracy: 1.0000\nEpoch 3/200\n5/5 [==============================] - 2s 500ms/step - loss: 2.2750 - accuracy: 0.9848 - val_loss: 2.1924 - val_accuracy: 1.0000\nEpoch 4/200\n5/5 [==============================] - 2s 494ms/step - loss: 2.2698 - accuracy: 0.9848 - val_loss: 2.1907 - val_accuracy: 1.0000\nEpoch 5/200\n5/5 [==============================] - 2s 487ms/step - loss: 2.3064 - accuracy: 0.9545 - val_loss: 2.1888 - val_accuracy: 1.0000\nEpoch 6/200\n5/5 [==============================] - 3s 503ms/step - loss: 2.2505 - accuracy: 1.0000 - val_loss: 2.1882 - val_accuracy: 1.0000\nEpoch 7/200\n5/5 [==============================] - 3s 493ms/step - loss: 2.3023 - accuracy: 0.9545 - val_loss: 2.1871 - val_accuracy: 1.0000\nEpoch 8/200\n5/5 [==============================] - 4s 842ms/step - loss: 2.2766 - accuracy: 0.9697 - val_loss: 2.1864 - val_accuracy: 1.0000\nEpoch 9/200\n5/5 [==============================] - 5s 952ms/step - loss: 2.2925 - accuracy: 0.9697 - val_loss: 2.1839 - val_accuracy: 1.0000\nEpoch 10/200\n5/5 [==============================] - 5s 1s/step - loss: 2.2895 - accuracy: 0.9697 - val_loss: 2.1802 - val_accuracy: 1.0000\nEpoch 11/200\n5/5 [==============================] - 4s 889ms/step - loss: 2.2370 - accuracy: 0.9848 - val_loss: 2.1768 - val_accuracy: 1.0000\nEpoch 12/200\n5/5 [==============================] - 4s 675ms/step - loss: 2.2435 - accuracy: 0.9848 - val_loss: 2.1741 - val_accuracy: 1.0000\nEpoch 13/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.2920 - accuracy: 0.9394 - val_loss: 2.1721 - val_accuracy: 1.0000\nEpoch 14/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.2235 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 1.0000\nEpoch 15/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.2512 - accuracy: 0.9848 - val_loss: 2.1680 - val_accuracy: 1.0000\nEpoch 16/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.2155 - accuracy: 1.0000 - val_loss: 2.1663 - val_accuracy: 1.0000\nEpoch 17/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.2203 - accuracy: 1.0000 - val_loss: 2.1643 - val_accuracy: 1.0000\nEpoch 18/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.2129 - accuracy: 0.9848 - val_loss: 2.1624 - val_accuracy: 1.0000\nEpoch 19/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.2076 - accuracy: 1.0000 - val_loss: 2.1607 - val_accuracy: 1.0000\nEpoch 20/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.2484 - accuracy: 0.9697 - val_loss: 2.1585 - val_accuracy: 1.0000\nEpoch 21/200\n5/5 [==============================] - 3s 515ms/step - loss: 2.2095 - accuracy: 1.0000 - val_loss: 2.1563 - val_accuracy: 1.0000\nEpoch 22/200\n5/5 [==============================] - 3s 512ms/step - loss: 2.2025 - accuracy: 1.0000 - val_loss: 2.1542 - val_accuracy: 1.0000\nEpoch 23/200\n5/5 [==============================] - 3s 503ms/step - loss: 2.1981 - accuracy: 1.0000 - val_loss: 2.1539 - val_accuracy: 1.0000\nEpoch 24/200\n5/5 [==============================] - 3s 502ms/step - loss: 2.1891 - accuracy: 1.0000 - val_loss: 2.1523 - val_accuracy: 1.0000\nEpoch 25/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.2047 - accuracy: 0.9848 - val_loss: 2.1497 - val_accuracy: 1.0000\nEpoch 26/200\n5/5 [==============================] - 3s 510ms/step - loss: 2.1760 - accuracy: 1.0000 - val_loss: 2.1464 - val_accuracy: 1.0000\nEpoch 27/200\n5/5 [==============================] - 3s 538ms/step - loss: 2.1847 - accuracy: 1.0000 - val_loss: 2.1429 - val_accuracy: 1.0000\nEpoch 28/200\n5/5 [==============================] - 3s 508ms/step - loss: 2.1741 - accuracy: 1.0000 - val_loss: 2.1395 - val_accuracy: 1.0000\nEpoch 29/200\n5/5 [==============================] - 3s 516ms/step - loss: 2.1806 - accuracy: 1.0000 - val_loss: 2.1377 - val_accuracy: 1.0000\nEpoch 30/200\n5/5 [==============================] - 3s 499ms/step - loss: 2.1666 - accuracy: 1.0000 - val_loss: 2.1360 - val_accuracy: 1.0000\nEpoch 31/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.1761 - accuracy: 1.0000 - val_loss: 2.1341 - val_accuracy: 1.0000\nEpoch 32/200\n5/5 [==============================] - 3s 507ms/step - loss: 2.1503 - accuracy: 1.0000 - val_loss: 2.1322 - val_accuracy: 1.0000\nEpoch 33/200\n5/5 [==============================] - 3s 505ms/step - loss: 2.1845 - accuracy: 0.9848 - val_loss: 2.1309 - val_accuracy: 1.0000\nEpoch 34/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.1527 - accuracy: 1.0000 - val_loss: 2.1298 - val_accuracy: 1.0000\nEpoch 35/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.1332 - accuracy: 1.0000 - val_loss: 2.1341 - val_accuracy: 1.0000\nEpoch 36/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.2175 - accuracy: 0.9697 - val_loss: 2.1332 - val_accuracy: 1.0000\nEpoch 37/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.1298 - accuracy: 1.0000 - val_loss: 2.1306 - val_accuracy: 1.0000\nEpoch 38/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.1564 - accuracy: 1.0000 - val_loss: 2.1296 - val_accuracy: 1.0000\nEpoch 39/200\n5/5 [==============================] - 3s 567ms/step - loss: 2.1557 - accuracy: 1.0000 - val_loss: 2.1270 - val_accuracy: 1.0000\nEpoch 40/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.1464 - accuracy: 1.0000 - val_loss: 2.1252 - val_accuracy: 1.0000\nEpoch 41/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.1231 - accuracy: 1.0000 - val_loss: 2.1228 - val_accuracy: 1.0000\nEpoch 42/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.1588 - accuracy: 0.9848 - val_loss: 2.1178 - val_accuracy: 1.0000\nEpoch 43/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.1705 - accuracy: 0.9697 - val_loss: 2.1117 - val_accuracy: 1.0000\nEpoch 44/200\n5/5 [==============================] - 3s 515ms/step - loss: 2.1177 - accuracy: 1.0000 - val_loss: 2.1055 - val_accuracy: 1.0000\nEpoch 45/200\n5/5 [==============================] - 3s 501ms/step - loss: 2.1396 - accuracy: 0.9848 - val_loss: 2.1003 - val_accuracy: 1.0000\nEpoch 46/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.1116 - accuracy: 1.0000 - val_loss: 2.0958 - val_accuracy: 1.0000\nEpoch 47/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.1187 - accuracy: 1.0000 - val_loss: 2.0915 - val_accuracy: 1.0000\nEpoch 48/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.1106 - accuracy: 1.0000 - val_loss: 2.0877 - val_accuracy: 1.0000\nEpoch 49/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.1165 - accuracy: 1.0000 - val_loss: 2.0842 - val_accuracy: 1.0000\nEpoch 50/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.1236 - accuracy: 0.9848 - val_loss: 2.0809 - val_accuracy: 1.0000\nEpoch 51/200\n5/5 [==============================] - 3s 561ms/step - loss: 2.0973 - accuracy: 1.0000 - val_loss: 2.0778 - val_accuracy: 1.0000\nEpoch 52/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.0996 - accuracy: 1.0000 - val_loss: 2.0752 - val_accuracy: 1.0000\nEpoch 53/200\n5/5 [==============================] - 3s 521ms/step - loss: 2.1059 - accuracy: 1.0000 - val_loss: 2.0736 - val_accuracy: 1.0000\nEpoch 54/200\n5/5 [==============================] - 3s 527ms/step - loss: 2.0830 - accuracy: 1.0000 - val_loss: 2.0720 - val_accuracy: 1.0000\nEpoch 55/200\n5/5 [==============================] - 3s 527ms/step - loss: 2.1248 - accuracy: 0.9848 - val_loss: 2.0706 - val_accuracy: 1.0000\nEpoch 56/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.0882 - accuracy: 1.0000 - val_loss: 2.0694 - val_accuracy: 1.0000\nEpoch 57/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.1044 - accuracy: 0.9848 - val_loss: 2.0678 - val_accuracy: 1.0000\nEpoch 58/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.0881 - accuracy: 1.0000 - val_loss: 2.0649 - val_accuracy: 1.0000\nEpoch 59/200\n5/5 [==============================] - 3s 534ms/step - loss: 2.0813 - accuracy: 1.0000 - val_loss: 2.0626 - val_accuracy: 1.0000\nEpoch 60/200\n5/5 [==============================] - 3s 509ms/step - loss: 2.0856 - accuracy: 1.0000 - val_loss: 2.0595 - val_accuracy: 1.0000\nEpoch 61/200\n5/5 [==============================] - 3s 530ms/step - loss: 2.0869 - accuracy: 0.9848 - val_loss: 2.0559 - val_accuracy: 1.0000\nEpoch 62/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.1401 - accuracy: 0.9848 - val_loss: 2.0548 - val_accuracy: 1.0000\nEpoch 63/200\n5/5 [==============================] - 3s 543ms/step - loss: 2.0564 - accuracy: 1.0000 - val_loss: 2.0556 - val_accuracy: 1.0000\nEpoch 64/200\n5/5 [==============================] - 3s 516ms/step - loss: 2.0531 - accuracy: 1.0000 - val_loss: 2.0558 - val_accuracy: 1.0000\nEpoch 65/200\n5/5 [==============================] - 3s 522ms/step - loss: 2.0914 - accuracy: 0.9848 - val_loss: 2.0553 - val_accuracy: 1.0000\nEpoch 66/200\n5/5 [==============================] - 3s 525ms/step - loss: 2.0495 - accuracy: 1.0000 - val_loss: 2.0597 - val_accuracy: 1.0000\nEpoch 67/200\n5/5 [==============================] - 3s 527ms/step - loss: 2.0575 - accuracy: 1.0000 - val_loss: 2.0596 - val_accuracy: 1.0000\nEpoch 68/200\n5/5 [==============================] - 3s 513ms/step - loss: 2.0431 - accuracy: 1.0000 - val_loss: 2.0584 - val_accuracy: 1.0000\nEpoch 69/200\n5/5 [==============================] - 3s 525ms/step - loss: 2.0745 - accuracy: 1.0000 - val_loss: 2.0537 - val_accuracy: 1.0000\nEpoch 70/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.0457 - accuracy: 1.0000 - val_loss: 2.0482 - val_accuracy: 1.0000\nEpoch 71/200\n5/5 [==============================] - 3s 532ms/step - loss: 2.0363 - accuracy: 1.0000 - val_loss: 2.0435 - val_accuracy: 1.0000\nEpoch 72/200\n5/5 [==============================] - 3s 536ms/step - loss: 2.0453 - accuracy: 0.9848 - val_loss: 2.0401 - val_accuracy: 1.0000\nEpoch 73/200\n5/5 [==============================] - 3s 529ms/step - loss: 2.0447 - accuracy: 1.0000 - val_loss: 2.0349 - val_accuracy: 1.0000\nEpoch 74/200\n5/5 [==============================] - 3s 550ms/step - loss: 2.0613 - accuracy: 0.9848 - val_loss: 2.0291 - val_accuracy: 1.0000\nEpoch 75/200\n5/5 [==============================] - 3s 518ms/step - loss: 2.0276 - accuracy: 1.0000 - val_loss: 2.0233 - val_accuracy: 1.0000\nEpoch 76/200\n5/5 [==============================] - 3s 533ms/step - loss: 2.0404 - accuracy: 0.9848 - val_loss: 2.0188 - val_accuracy: 1.0000\nEpoch 77/200\n5/5 [==============================] - 3s 514ms/step - loss: 2.0296 - accuracy: 1.0000 - val_loss: 2.0145 - val_accuracy: 1.0000\nEpoch 78/200\n5/5 [==============================] - 3s 517ms/step - loss: 2.0222 - accuracy: 1.0000 - val_loss: 2.0112 - val_accuracy: 1.0000\nEpoch 79/200\n5/5 [==============================] - 3s 511ms/step - loss: 2.0242 - accuracy: 1.0000 - val_loss: 2.0080 - val_accuracy: 1.0000\nEpoch 80/200\n5/5 [==============================] - 3s 520ms/step - loss: 2.0217 - accuracy: 1.0000 - val_loss: 2.0052 - val_accuracy: 1.0000\nEpoch 81/200\n5/5 [==============================] - 3s 526ms/step - loss: 2.0091 - accuracy: 1.0000 - val_loss: 2.0056 - val_accuracy: 1.0000\nEpoch 82/200\n5/5 [==============================] - 3s 521ms/step - loss: 2.0391 - accuracy: 0.9848 - val_loss: 2.0036 - val_accuracy: 1.0000\nEpoch 83/200\n5/5 [==============================] - 3s 530ms/step - loss: 2.0014 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 1.0000\nEpoch 84/200\n5/5 [==============================] - 3s 524ms/step - loss: 2.0142 - accuracy: 1.0000 - val_loss: 1.9988 - val_accuracy: 1.0000\nEpoch 85/200\n5/5 [==============================] - 3s 533ms/step - loss: 2.0036 - accuracy: 1.0000 - val_loss: 1.9968 - val_accuracy: 1.0000\nEpoch 86/200\n5/5 [==============================] - 3s 563ms/step - loss: 1.9948 - accuracy: 1.0000 - val_loss: 1.9949 - val_accuracy: 1.0000\nEpoch 87/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.9959 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 1.0000\nEpoch 88/200\n5/5 [==============================] - 3s 535ms/step - loss: 2.0139 - accuracy: 0.9848 - val_loss: 1.9918 - val_accuracy: 1.0000\nEpoch 89/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.9869 - accuracy: 1.0000 - val_loss: 1.9868 - val_accuracy: 1.0000\nEpoch 90/200\n5/5 [==============================] - 3s 511ms/step - loss: 1.9881 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 1.0000\nEpoch 91/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.9809 - accuracy: 1.0000 - val_loss: 1.9817 - val_accuracy: 1.0000\nEpoch 92/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.9807 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 1.0000\nEpoch 93/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.9878 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 1.0000\nEpoch 94/200\n5/5 [==============================] - 3s 536ms/step - loss: 1.9839 - accuracy: 1.0000 - val_loss: 1.9739 - val_accuracy: 1.0000\nEpoch 95/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.9801 - accuracy: 1.0000 - val_loss: 1.9713 - val_accuracy: 1.0000\nEpoch 96/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.9762 - accuracy: 1.0000 - val_loss: 1.9677 - val_accuracy: 1.0000\nEpoch 97/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.9734 - accuracy: 1.0000 - val_loss: 1.9644 - val_accuracy: 1.0000\nEpoch 98/200\n5/5 [==============================] - 3s 539ms/step - loss: 1.9621 - accuracy: 1.0000 - val_loss: 1.9616 - val_accuracy: 1.0000\nEpoch 99/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.9663 - accuracy: 1.0000 - val_loss: 1.9592 - val_accuracy: 1.0000\nEpoch 100/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.9541 - accuracy: 1.0000 - val_loss: 1.9571 - val_accuracy: 1.0000\nEpoch 101/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.9648 - accuracy: 1.0000 - val_loss: 1.9557 - val_accuracy: 1.0000\nEpoch 102/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.9665 - accuracy: 1.0000 - val_loss: 1.9533 - val_accuracy: 1.0000\nEpoch 103/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.9506 - accuracy: 1.0000 - val_loss: 1.9510 - val_accuracy: 1.0000\nEpoch 104/200\n5/5 [==============================] - 3s 533ms/step - loss: 1.9471 - accuracy: 1.0000 - val_loss: 1.9483 - val_accuracy: 1.0000\nEpoch 105/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.9532 - accuracy: 1.0000 - val_loss: 1.9448 - val_accuracy: 1.0000\nEpoch 106/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.9451 - accuracy: 1.0000 - val_loss: 1.9414 - val_accuracy: 1.0000\nEpoch 107/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.9439 - accuracy: 1.0000 - val_loss: 1.9383 - val_accuracy: 1.0000\nEpoch 108/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.9459 - accuracy: 1.0000 - val_loss: 1.9347 - val_accuracy: 1.0000\nEpoch 109/200\n5/5 [==============================] - 3s 550ms/step - loss: 1.9394 - accuracy: 1.0000 - val_loss: 1.9311 - val_accuracy: 1.0000\nEpoch 110/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.9386 - accuracy: 1.0000 - val_loss: 1.9277 - val_accuracy: 1.0000\nEpoch 111/200\n5/5 [==============================] - 3s 519ms/step - loss: 1.9242 - accuracy: 1.0000 - val_loss: 1.9245 - val_accuracy: 1.0000\nEpoch 112/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.9287 - accuracy: 1.0000 - val_loss: 1.9215 - val_accuracy: 1.0000\nEpoch 113/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.9234 - accuracy: 1.0000 - val_loss: 1.9188 - val_accuracy: 1.0000\nEpoch 114/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.9206 - accuracy: 1.0000 - val_loss: 1.9164 - val_accuracy: 1.0000\nEpoch 115/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.9205 - accuracy: 1.0000 - val_loss: 1.9138 - val_accuracy: 1.0000\nEpoch 116/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.9280 - accuracy: 1.0000 - val_loss: 1.9117 - val_accuracy: 1.0000\nEpoch 117/200\n5/5 [==============================] - 3s 538ms/step - loss: 1.9147 - accuracy: 1.0000 - val_loss: 1.9094 - val_accuracy: 1.0000\nEpoch 118/200\n5/5 [==============================] - 3s 514ms/step - loss: 1.9199 - accuracy: 1.0000 - val_loss: 1.9069 - val_accuracy: 1.0000\nEpoch 119/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.9016 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 1.0000\nEpoch 120/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.9065 - accuracy: 1.0000 - val_loss: 1.9021 - val_accuracy: 1.0000\nEpoch 121/200\n5/5 [==============================] - 3s 566ms/step - loss: 1.9032 - accuracy: 1.0000 - val_loss: 1.8999 - val_accuracy: 1.0000\nEpoch 122/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.8967 - accuracy: 1.0000 - val_loss: 1.8974 - val_accuracy: 1.0000\nEpoch 123/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.8984 - accuracy: 1.0000 - val_loss: 1.8946 - val_accuracy: 1.0000\nEpoch 124/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.8913 - accuracy: 1.0000 - val_loss: 1.8916 - val_accuracy: 1.0000\nEpoch 125/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.9203 - accuracy: 0.9848 - val_loss: 1.8894 - val_accuracy: 1.0000\nEpoch 126/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.8897 - accuracy: 1.0000 - val_loss: 1.8859 - val_accuracy: 1.0000\nEpoch 127/200\n5/5 [==============================] - 3s 512ms/step - loss: 1.8897 - accuracy: 1.0000 - val_loss: 1.8833 - val_accuracy: 1.0000\nEpoch 128/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.8808 - accuracy: 1.0000 - val_loss: 1.8806 - val_accuracy: 1.0000\nEpoch 129/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.8943 - accuracy: 1.0000 - val_loss: 1.8773 - val_accuracy: 1.0000\nEpoch 130/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.8815 - accuracy: 1.0000 - val_loss: 1.8746 - val_accuracy: 1.0000\nEpoch 131/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.8740 - accuracy: 1.0000 - val_loss: 1.8713 - val_accuracy: 1.0000\nEpoch 132/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.8989 - accuracy: 0.9848 - val_loss: 1.8676 - val_accuracy: 1.0000\nEpoch 133/200\n5/5 [==============================] - 3s 568ms/step - loss: 1.8819 - accuracy: 1.0000 - val_loss: 1.8643 - val_accuracy: 1.0000\nEpoch 134/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.8721 - accuracy: 1.0000 - val_loss: 1.8618 - val_accuracy: 1.0000\nEpoch 135/200\n5/5 [==============================] - 3s 533ms/step - loss: 1.8737 - accuracy: 1.0000 - val_loss: 1.8592 - val_accuracy: 1.0000\nEpoch 136/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.8689 - accuracy: 1.0000 - val_loss: 1.8565 - val_accuracy: 1.0000\nEpoch 137/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.8689 - accuracy: 1.0000 - val_loss: 1.8541 - val_accuracy: 1.0000\nEpoch 138/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.8536 - accuracy: 1.0000 - val_loss: 1.8517 - val_accuracy: 1.0000\nEpoch 139/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.8632 - accuracy: 1.0000 - val_loss: 1.8492 - val_accuracy: 1.0000\nEpoch 140/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.8677 - accuracy: 0.9848 - val_loss: 1.8475 - val_accuracy: 1.0000\nEpoch 141/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.8636 - accuracy: 1.0000 - val_loss: 1.8456 - val_accuracy: 1.0000\nEpoch 142/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.8631 - accuracy: 0.9848 - val_loss: 1.8448 - val_accuracy: 1.0000\nEpoch 143/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.8585 - accuracy: 1.0000 - val_loss: 1.8430 - val_accuracy: 1.0000\nEpoch 144/200\n5/5 [==============================] - 3s 544ms/step - loss: 1.8372 - accuracy: 1.0000 - val_loss: 1.8409 - val_accuracy: 1.0000\nEpoch 145/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.8434 - accuracy: 1.0000 - val_loss: 1.8416 - val_accuracy: 1.0000\nEpoch 146/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.8396 - accuracy: 1.0000 - val_loss: 1.8400 - val_accuracy: 1.0000\nEpoch 147/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.8347 - accuracy: 1.0000 - val_loss: 1.8383 - val_accuracy: 1.0000\nEpoch 148/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.8315 - accuracy: 1.0000 - val_loss: 1.8359 - val_accuracy: 1.0000\nEpoch 149/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.8332 - accuracy: 1.0000 - val_loss: 1.8331 - val_accuracy: 1.0000\nEpoch 150/200\n5/5 [==============================] - 3s 539ms/step - loss: 1.8243 - accuracy: 1.0000 - val_loss: 1.8307 - val_accuracy: 1.0000\nEpoch 151/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.8495 - accuracy: 0.9848 - val_loss: 1.8260 - val_accuracy: 1.0000\nEpoch 152/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.8204 - accuracy: 1.0000 - val_loss: 1.8215 - val_accuracy: 1.0000\nEpoch 153/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.8261 - accuracy: 1.0000 - val_loss: 1.8182 - val_accuracy: 1.0000\nEpoch 154/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.8170 - accuracy: 1.0000 - val_loss: 1.8154 - val_accuracy: 1.0000\nEpoch 155/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.8173 - accuracy: 1.0000 - val_loss: 1.8116 - val_accuracy: 1.0000\nEpoch 156/200\n5/5 [==============================] - 3s 552ms/step - loss: 1.8087 - accuracy: 1.0000 - val_loss: 1.8087 - val_accuracy: 1.0000\nEpoch 157/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.8027 - accuracy: 1.0000 - val_loss: 1.8058 - val_accuracy: 1.0000\nEpoch 158/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.8195 - accuracy: 1.0000 - val_loss: 1.8038 - val_accuracy: 1.0000\nEpoch 159/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.8018 - accuracy: 1.0000 - val_loss: 1.8016 - val_accuracy: 1.0000\nEpoch 160/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.7995 - accuracy: 1.0000 - val_loss: 1.7994 - val_accuracy: 1.0000\nEpoch 161/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.8005 - accuracy: 1.0000 - val_loss: 1.7971 - val_accuracy: 1.0000\nEpoch 162/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.7896 - accuracy: 1.0000 - val_loss: 1.7987 - val_accuracy: 1.0000\nEpoch 163/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.8245 - accuracy: 0.9848 - val_loss: 1.7951 - val_accuracy: 1.0000\nEpoch 164/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.7971 - accuracy: 1.0000 - val_loss: 1.7837 - val_accuracy: 1.0000\nEpoch 165/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.8037 - accuracy: 1.0000 - val_loss: 1.7822 - val_accuracy: 1.0000\nEpoch 166/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.7984 - accuracy: 1.0000 - val_loss: 1.7805 - val_accuracy: 1.0000\nEpoch 167/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.7910 - accuracy: 1.0000 - val_loss: 1.7780 - val_accuracy: 1.0000\nEpoch 168/200\n5/5 [==============================] - 3s 559ms/step - loss: 1.7807 - accuracy: 1.0000 - val_loss: 1.7752 - val_accuracy: 1.0000\nEpoch 169/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.7795 - accuracy: 1.0000 - val_loss: 1.7725 - val_accuracy: 1.0000\nEpoch 170/200\n5/5 [==============================] - 3s 508ms/step - loss: 1.8252 - accuracy: 0.9848 - val_loss: 1.7702 - val_accuracy: 1.0000\nEpoch 171/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.7846 - accuracy: 1.0000 - val_loss: 1.7687 - val_accuracy: 1.0000\nEpoch 172/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.7800 - accuracy: 1.0000 - val_loss: 1.7679 - val_accuracy: 1.0000\nEpoch 173/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.7639 - accuracy: 1.0000 - val_loss: 1.7673 - val_accuracy: 1.0000\nEpoch 174/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.7827 - accuracy: 1.0000 - val_loss: 1.7657 - val_accuracy: 1.0000\nEpoch 175/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.7650 - accuracy: 1.0000 - val_loss: 1.7623 - val_accuracy: 1.0000\nEpoch 176/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.7613 - accuracy: 1.0000 - val_loss: 1.7608 - val_accuracy: 1.0000\nEpoch 177/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.7589 - accuracy: 1.0000 - val_loss: 1.7583 - val_accuracy: 1.0000\nEpoch 178/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.7593 - accuracy: 1.0000 - val_loss: 1.7560 - val_accuracy: 1.0000\nEpoch 179/200\n5/5 [==============================] - 3s 550ms/step - loss: 1.7598 - accuracy: 1.0000 - val_loss: 1.7540 - val_accuracy: 1.0000\nEpoch 180/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.7501 - accuracy: 1.0000 - val_loss: 1.7515 - val_accuracy: 1.0000\nEpoch 181/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.7472 - accuracy: 1.0000 - val_loss: 1.7498 - val_accuracy: 1.0000\nEpoch 182/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.7426 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 1.0000\nEpoch 183/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.7538 - accuracy: 1.0000 - val_loss: 1.7464 - val_accuracy: 1.0000\nEpoch 184/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.7392 - accuracy: 1.0000 - val_loss: 1.7449 - val_accuracy: 1.0000\nEpoch 185/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.7462 - accuracy: 1.0000 - val_loss: 1.7428 - val_accuracy: 1.0000\nEpoch 186/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.7374 - accuracy: 1.0000 - val_loss: 1.7405 - val_accuracy: 1.0000\nEpoch 187/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.7337 - accuracy: 1.0000 - val_loss: 1.7391 - val_accuracy: 1.0000\nEpoch 188/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.7304 - accuracy: 1.0000 - val_loss: 1.7370 - val_accuracy: 1.0000\nEpoch 189/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.7264 - accuracy: 1.0000 - val_loss: 1.7409 - val_accuracy: 1.0000\nEpoch 190/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.7223 - accuracy: 1.0000 - val_loss: 1.7466 - val_accuracy: 1.0000\nEpoch 191/200\n5/5 [==============================] - 3s 564ms/step - loss: 1.7433 - accuracy: 0.9848 - val_loss: 1.7494 - val_accuracy: 1.0000\nEpoch 192/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.7181 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 1.0000\nEpoch 193/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.7213 - accuracy: 1.0000 - val_loss: 1.7324 - val_accuracy: 1.0000\nEpoch 194/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.7241 - accuracy: 1.0000 - val_loss: 1.7294 - val_accuracy: 1.0000\nEpoch 195/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.7208 - accuracy: 1.0000 - val_loss: 1.7266 - val_accuracy: 1.0000\nEpoch 196/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.7182 - accuracy: 1.0000 - val_loss: 1.7237 - val_accuracy: 1.0000\nEpoch 197/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.7300 - accuracy: 1.0000 - val_loss: 1.7202 - val_accuracy: 1.0000\nEpoch 198/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.7096 - accuracy: 1.0000 - val_loss: 1.7174 - val_accuracy: 1.0000\nEpoch 199/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.7082 - accuracy: 1.0000 - val_loss: 1.7210 - val_accuracy: 1.0000\nEpoch 200/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.7235 - accuracy: 0.9848 - val_loss: 1.7180 - val_accuracy: 1.0000\n3/3 [==============================] - 1s 156ms/step - loss: 1.6929 - accuracy: 1.0000\n1/1 [==============================] - 0s 246ms/step - loss: 1.7180 - accuracy: 1.0000\n1/1 [==============================] - 0s 240ms/step\nEpoch 1/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.7158 - accuracy: 1.0000 - val_loss: 1.6889 - val_accuracy: 1.0000\nEpoch 2/200\n5/5 [==============================] - 2s 508ms/step - loss: 1.7165 - accuracy: 1.0000 - val_loss: 1.6864 - val_accuracy: 1.0000\nEpoch 3/200\n5/5 [==============================] - 2s 471ms/step - loss: 1.7160 - accuracy: 1.0000 - val_loss: 1.6839 - val_accuracy: 1.0000\nEpoch 4/200\n5/5 [==============================] - 2s 468ms/step - loss: 1.7056 - accuracy: 1.0000 - val_loss: 1.6814 - val_accuracy: 1.0000\nEpoch 5/200\n5/5 [==============================] - 2s 470ms/step - loss: 1.7045 - accuracy: 1.0000 - val_loss: 1.6789 - val_accuracy: 1.0000\nEpoch 6/200\n5/5 [==============================] - 2s 478ms/step - loss: 1.7011 - accuracy: 1.0000 - val_loss: 1.6764 - val_accuracy: 1.0000\nEpoch 7/200\n5/5 [==============================] - 2s 474ms/step - loss: 1.7113 - accuracy: 0.9848 - val_loss: 1.6739 - val_accuracy: 1.0000\nEpoch 8/200\n5/5 [==============================] - 2s 462ms/step - loss: 1.6994 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 1.0000\nEpoch 9/200\n5/5 [==============================] - 2s 485ms/step - loss: 1.6894 - accuracy: 1.0000 - val_loss: 1.6689 - val_accuracy: 1.0000\nEpoch 10/200\n5/5 [==============================] - 2s 474ms/step - loss: 1.6845 - accuracy: 1.0000 - val_loss: 1.6665 - val_accuracy: 1.0000\nEpoch 11/200\n5/5 [==============================] - 2s 473ms/step - loss: 1.6844 - accuracy: 1.0000 - val_loss: 1.6640 - val_accuracy: 1.0000\nEpoch 12/200\n5/5 [==============================] - 2s 482ms/step - loss: 1.6853 - accuracy: 1.0000 - val_loss: 1.6615 - val_accuracy: 1.0000\nEpoch 13/200\n5/5 [==============================] - 2s 478ms/step - loss: 1.6921 - accuracy: 0.9848 - val_loss: 1.6591 - val_accuracy: 1.0000\nEpoch 14/200\n5/5 [==============================] - 2s 481ms/step - loss: 1.7302 - accuracy: 0.9848 - val_loss: 1.6569 - val_accuracy: 1.0000\nEpoch 15/200\n5/5 [==============================] - 3s 509ms/step - loss: 1.6963 - accuracy: 0.9848 - val_loss: 1.6584 - val_accuracy: 1.0000\nEpoch 16/200\n5/5 [==============================] - 2s 474ms/step - loss: 1.6923 - accuracy: 1.0000 - val_loss: 1.6636 - val_accuracy: 1.0000\nEpoch 17/200\n5/5 [==============================] - 2s 484ms/step - loss: 1.6828 - accuracy: 1.0000 - val_loss: 1.6664 - val_accuracy: 1.0000\nEpoch 18/200\n5/5 [==============================] - 2s 487ms/step - loss: 1.6820 - accuracy: 1.0000 - val_loss: 1.6643 - val_accuracy: 1.0000\nEpoch 19/200\n5/5 [==============================] - 2s 486ms/step - loss: 1.6842 - accuracy: 0.9848 - val_loss: 1.6595 - val_accuracy: 1.0000\nEpoch 20/200\n5/5 [==============================] - 2s 479ms/step - loss: 1.6954 - accuracy: 0.9848 - val_loss: 1.6533 - val_accuracy: 1.0000\nEpoch 21/200\n5/5 [==============================] - 2s 480ms/step - loss: 1.6737 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 1.0000\nEpoch 22/200\n5/5 [==============================] - 2s 488ms/step - loss: 1.6597 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 1.0000\nEpoch 23/200\n5/5 [==============================] - 2s 495ms/step - loss: 1.6528 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 1.0000\nEpoch 24/200\n5/5 [==============================] - 2s 484ms/step - loss: 1.6652 - accuracy: 1.0000 - val_loss: 1.6373 - val_accuracy: 1.0000\nEpoch 25/200\n5/5 [==============================] - 2s 488ms/step - loss: 1.6571 - accuracy: 1.0000 - val_loss: 1.6345 - val_accuracy: 1.0000\nEpoch 26/200\n5/5 [==============================] - 2s 480ms/step - loss: 1.6438 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 1.0000\nEpoch 27/200\n5/5 [==============================] - 2s 490ms/step - loss: 1.6583 - accuracy: 0.9848 - val_loss: 1.6294 - val_accuracy: 1.0000\nEpoch 28/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.6569 - accuracy: 0.9848 - val_loss: 1.6271 - val_accuracy: 1.0000\nEpoch 29/200\n5/5 [==============================] - 5s 1s/step - loss: 1.6515 - accuracy: 0.9848 - val_loss: 1.6250 - val_accuracy: 1.0000\nEpoch 30/200\n5/5 [==============================] - 6s 1s/step - loss: 1.6390 - accuracy: 1.0000 - val_loss: 1.6233 - val_accuracy: 1.0000\nEpoch 31/200\n5/5 [==============================] - 3s 597ms/step - loss: 1.6363 - accuracy: 1.0000 - val_loss: 1.6213 - val_accuracy: 1.0000\nEpoch 32/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.6483 - accuracy: 1.0000 - val_loss: 1.6193 - val_accuracy: 1.0000\nEpoch 33/200\n5/5 [==============================] - 3s 502ms/step - loss: 1.6278 - accuracy: 1.0000 - val_loss: 1.6170 - val_accuracy: 1.0000\nEpoch 34/200\n5/5 [==============================] - 3s 493ms/step - loss: 1.6252 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 1.0000\nEpoch 35/200\n5/5 [==============================] - 2s 491ms/step - loss: 1.6210 - accuracy: 1.0000 - val_loss: 1.6123 - val_accuracy: 1.0000\nEpoch 36/200\n5/5 [==============================] - 2s 492ms/step - loss: 1.6210 - accuracy: 1.0000 - val_loss: 1.6098 - val_accuracy: 1.0000\nEpoch 37/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.6220 - accuracy: 1.0000 - val_loss: 1.6072 - val_accuracy: 1.0000\nEpoch 38/200\n5/5 [==============================] - 3s 511ms/step - loss: 1.6180 - accuracy: 1.0000 - val_loss: 1.6046 - val_accuracy: 1.0000\nEpoch 39/200\n5/5 [==============================] - 2s 494ms/step - loss: 1.6199 - accuracy: 1.0000 - val_loss: 1.6021 - val_accuracy: 1.0000\nEpoch 40/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.6126 - accuracy: 1.0000 - val_loss: 1.5995 - val_accuracy: 1.0000\nEpoch 41/200\n5/5 [==============================] - 3s 512ms/step - loss: 1.6065 - accuracy: 1.0000 - val_loss: 1.5970 - val_accuracy: 1.0000\nEpoch 42/200\n5/5 [==============================] - 3s 509ms/step - loss: 1.6017 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 1.0000\nEpoch 43/200\n5/5 [==============================] - 3s 503ms/step - loss: 1.6068 - accuracy: 1.0000 - val_loss: 1.5922 - val_accuracy: 1.0000\nEpoch 44/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.6018 - accuracy: 1.0000 - val_loss: 1.5900 - val_accuracy: 1.0000\nEpoch 45/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.6096 - accuracy: 0.9848 - val_loss: 1.5884 - val_accuracy: 1.0000\nEpoch 46/200\n5/5 [==============================] - 3s 498ms/step - loss: 1.6018 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 1.0000\nEpoch 47/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.5954 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 1.0000\nEpoch 48/200\n5/5 [==============================] - 3s 501ms/step - loss: 1.5894 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 1.0000\nEpoch 49/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.5956 - accuracy: 1.0000 - val_loss: 1.5802 - val_accuracy: 1.0000\nEpoch 50/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.5855 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 1.0000\nEpoch 51/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.5824 - accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 1.0000\nEpoch 52/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.5993 - accuracy: 0.9848 - val_loss: 1.5724 - val_accuracy: 1.0000\nEpoch 53/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.5759 - accuracy: 1.0000 - val_loss: 1.5697 - val_accuracy: 1.0000\nEpoch 54/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.5718 - accuracy: 1.0000 - val_loss: 1.5671 - val_accuracy: 1.0000\nEpoch 55/200\n5/5 [==============================] - 3s 509ms/step - loss: 1.5688 - accuracy: 1.0000 - val_loss: 1.5650 - val_accuracy: 1.0000\nEpoch 56/200\n5/5 [==============================] - 3s 504ms/step - loss: 1.5755 - accuracy: 1.0000 - val_loss: 1.5625 - val_accuracy: 1.0000\nEpoch 57/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.5758 - accuracy: 1.0000 - val_loss: 1.5604 - val_accuracy: 1.0000\nEpoch 58/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.5731 - accuracy: 1.0000 - val_loss: 1.5581 - val_accuracy: 1.0000\nEpoch 59/200\n5/5 [==============================] - 3s 503ms/step - loss: 1.5694 - accuracy: 1.0000 - val_loss: 1.5556 - val_accuracy: 1.0000\nEpoch 60/200\n5/5 [==============================] - 3s 505ms/step - loss: 1.5630 - accuracy: 1.0000 - val_loss: 1.5532 - val_accuracy: 1.0000\nEpoch 61/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.5650 - accuracy: 1.0000 - val_loss: 1.5508 - val_accuracy: 1.0000\nEpoch 62/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.5711 - accuracy: 0.9848 - val_loss: 1.5483 - val_accuracy: 1.0000\nEpoch 63/200\n5/5 [==============================] - 2s 498ms/step - loss: 1.5563 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 1.0000\nEpoch 64/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.5637 - accuracy: 1.0000 - val_loss: 1.5434 - val_accuracy: 1.0000\nEpoch 65/200\n5/5 [==============================] - 3s 504ms/step - loss: 1.5494 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 1.0000\nEpoch 66/200\n5/5 [==============================] - 3s 498ms/step - loss: 1.5523 - accuracy: 1.0000 - val_loss: 1.5386 - val_accuracy: 1.0000\nEpoch 67/200\n5/5 [==============================] - 3s 494ms/step - loss: 1.5408 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 1.0000\nEpoch 68/200\n5/5 [==============================] - 3s 502ms/step - loss: 1.5446 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 1.0000\nEpoch 69/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.5382 - accuracy: 1.0000 - val_loss: 1.5314 - val_accuracy: 1.0000\nEpoch 70/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.5361 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 1.0000\nEpoch 71/200\n5/5 [==============================] - 3s 502ms/step - loss: 1.5386 - accuracy: 1.0000 - val_loss: 1.5266 - val_accuracy: 1.0000\nEpoch 72/200\n5/5 [==============================] - 4s 872ms/step - loss: 1.5464 - accuracy: 0.9848 - val_loss: 1.5243 - val_accuracy: 1.0000\nEpoch 73/200\n5/5 [==============================] - 5s 955ms/step - loss: 1.5325 - accuracy: 1.0000 - val_loss: 1.5220 - val_accuracy: 1.0000\nEpoch 74/200\n5/5 [==============================] - 4s 803ms/step - loss: 1.5271 - accuracy: 1.0000 - val_loss: 1.5197 - val_accuracy: 1.0000\nEpoch 75/200\n5/5 [==============================] - 3s 589ms/step - loss: 1.5275 - accuracy: 1.0000 - val_loss: 1.5174 - val_accuracy: 1.0000\nEpoch 76/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.5221 - accuracy: 1.0000 - val_loss: 1.5150 - val_accuracy: 1.0000\nEpoch 77/200\n5/5 [==============================] - 3s 498ms/step - loss: 1.5253 - accuracy: 1.0000 - val_loss: 1.5126 - val_accuracy: 1.0000\nEpoch 78/200\n5/5 [==============================] - 3s 511ms/step - loss: 1.5181 - accuracy: 1.0000 - val_loss: 1.5102 - val_accuracy: 1.0000\nEpoch 79/200\n5/5 [==============================] - 3s 512ms/step - loss: 1.5174 - accuracy: 1.0000 - val_loss: 1.5078 - val_accuracy: 1.0000\nEpoch 80/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.5132 - accuracy: 1.0000 - val_loss: 1.5054 - val_accuracy: 1.0000\nEpoch 81/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.5144 - accuracy: 1.0000 - val_loss: 1.5030 - val_accuracy: 1.0000\nEpoch 82/200\n5/5 [==============================] - 3s 504ms/step - loss: 1.5088 - accuracy: 1.0000 - val_loss: 1.5006 - val_accuracy: 1.0000\nEpoch 83/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.5116 - accuracy: 1.0000 - val_loss: 1.4982 - val_accuracy: 1.0000\nEpoch 84/200\n5/5 [==============================] - 3s 553ms/step - loss: 1.5085 - accuracy: 1.0000 - val_loss: 1.4959 - val_accuracy: 1.0000\nEpoch 85/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.5017 - accuracy: 1.0000 - val_loss: 1.4935 - val_accuracy: 1.0000\nEpoch 86/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.5031 - accuracy: 1.0000 - val_loss: 1.4912 - val_accuracy: 1.0000\nEpoch 87/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.4980 - accuracy: 1.0000 - val_loss: 1.4889 - val_accuracy: 1.0000\nEpoch 88/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.5061 - accuracy: 1.0000 - val_loss: 1.4866 - val_accuracy: 1.0000\nEpoch 89/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.4897 - accuracy: 1.0000 - val_loss: 1.4843 - val_accuracy: 1.0000\nEpoch 90/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.4897 - accuracy: 1.0000 - val_loss: 1.4820 - val_accuracy: 1.0000\nEpoch 91/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.4838 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 1.0000\nEpoch 92/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.4881 - accuracy: 1.0000 - val_loss: 1.4773 - val_accuracy: 1.0000\nEpoch 93/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.4918 - accuracy: 1.0000 - val_loss: 1.4749 - val_accuracy: 1.0000\nEpoch 94/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.4852 - accuracy: 1.0000 - val_loss: 1.4725 - val_accuracy: 1.0000\nEpoch 95/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.4802 - accuracy: 1.0000 - val_loss: 1.4701 - val_accuracy: 1.0000\nEpoch 96/200\n5/5 [==============================] - 3s 559ms/step - loss: 1.4735 - accuracy: 1.0000 - val_loss: 1.4678 - val_accuracy: 1.0000\nEpoch 97/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.4745 - accuracy: 1.0000 - val_loss: 1.4654 - val_accuracy: 1.0000\nEpoch 98/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.4764 - accuracy: 1.0000 - val_loss: 1.4631 - val_accuracy: 1.0000\nEpoch 99/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.4683 - accuracy: 1.0000 - val_loss: 1.4608 - val_accuracy: 1.0000\nEpoch 100/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.4652 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 1.0000\nEpoch 101/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.4808 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 1.0000\nEpoch 102/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.4680 - accuracy: 1.0000 - val_loss: 1.4542 - val_accuracy: 1.0000\nEpoch 103/200\n5/5 [==============================] - 3s 539ms/step - loss: 1.4560 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 1.0000\nEpoch 104/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.4582 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 1.0000\nEpoch 105/200\n5/5 [==============================] - 3s 538ms/step - loss: 1.4522 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 1.0000\nEpoch 106/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.4536 - accuracy: 1.0000 - val_loss: 1.4450 - val_accuracy: 1.0000\nEpoch 107/200\n5/5 [==============================] - 3s 566ms/step - loss: 1.4497 - accuracy: 1.0000 - val_loss: 1.4427 - val_accuracy: 1.0000\nEpoch 108/200\n5/5 [==============================] - 3s 544ms/step - loss: 1.4454 - accuracy: 1.0000 - val_loss: 1.4405 - val_accuracy: 1.0000\nEpoch 109/200\n5/5 [==============================] - 3s 536ms/step - loss: 1.4563 - accuracy: 1.0000 - val_loss: 1.4382 - val_accuracy: 1.0000\nEpoch 110/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.4457 - accuracy: 1.0000 - val_loss: 1.4360 - val_accuracy: 1.0000\nEpoch 111/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.4390 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 1.0000\nEpoch 112/200\n5/5 [==============================] - 3s 549ms/step - loss: 1.4449 - accuracy: 1.0000 - val_loss: 1.4315 - val_accuracy: 1.0000\nEpoch 113/200\n5/5 [==============================] - 3s 546ms/step - loss: 1.4402 - accuracy: 1.0000 - val_loss: 1.4296 - val_accuracy: 1.0000\nEpoch 114/200\n5/5 [==============================] - 3s 540ms/step - loss: 1.4306 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 1.0000\nEpoch 115/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.4349 - accuracy: 1.0000 - val_loss: 1.4252 - val_accuracy: 1.0000\nEpoch 116/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.4289 - accuracy: 1.0000 - val_loss: 1.4229 - val_accuracy: 1.0000\nEpoch 117/200\n5/5 [==============================] - 3s 545ms/step - loss: 1.4282 - accuracy: 1.0000 - val_loss: 1.4205 - val_accuracy: 1.0000\nEpoch 118/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.4258 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 1.0000\nEpoch 119/200\n5/5 [==============================] - 3s 558ms/step - loss: 1.4204 - accuracy: 1.0000 - val_loss: 1.4158 - val_accuracy: 1.0000\nEpoch 120/200\n5/5 [==============================] - 3s 550ms/step - loss: 1.4341 - accuracy: 1.0000 - val_loss: 1.4136 - val_accuracy: 1.0000\nEpoch 121/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.4255 - accuracy: 1.0000 - val_loss: 1.4114 - val_accuracy: 1.0000\nEpoch 122/200\n5/5 [==============================] - 3s 533ms/step - loss: 1.4130 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 1.0000\nEpoch 123/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.4193 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 1.0000\nEpoch 124/200\n5/5 [==============================] - 3s 536ms/step - loss: 1.4124 - accuracy: 1.0000 - val_loss: 1.4047 - val_accuracy: 1.0000\nEpoch 125/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.4117 - accuracy: 1.0000 - val_loss: 1.4024 - val_accuracy: 1.0000\nEpoch 126/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.4054 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 1.0000\nEpoch 127/200\n5/5 [==============================] - 3s 540ms/step - loss: 1.4099 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 1.0000\nEpoch 128/200\n5/5 [==============================] - 3s 540ms/step - loss: 1.4097 - accuracy: 1.0000 - val_loss: 1.3956 - val_accuracy: 1.0000\nEpoch 129/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.4082 - accuracy: 1.0000 - val_loss: 1.3932 - val_accuracy: 1.0000\nEpoch 130/200\n5/5 [==============================] - 3s 566ms/step - loss: 1.4033 - accuracy: 1.0000 - val_loss: 1.3908 - val_accuracy: 1.0000\nEpoch 131/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.3932 - accuracy: 1.0000 - val_loss: 1.3885 - val_accuracy: 1.0000\nEpoch 132/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.3917 - accuracy: 1.0000 - val_loss: 1.3862 - val_accuracy: 1.0000\nEpoch 133/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.3922 - accuracy: 1.0000 - val_loss: 1.3839 - val_accuracy: 1.0000\nEpoch 134/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.3902 - accuracy: 1.0000 - val_loss: 1.3816 - val_accuracy: 1.0000\nEpoch 135/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.3885 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 1.0000\nEpoch 136/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.3834 - accuracy: 1.0000 - val_loss: 1.3771 - val_accuracy: 1.0000\nEpoch 137/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.3815 - accuracy: 1.0000 - val_loss: 1.3748 - val_accuracy: 1.0000\nEpoch 138/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.3826 - accuracy: 1.0000 - val_loss: 1.3726 - val_accuracy: 1.0000\nEpoch 139/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.3807 - accuracy: 1.0000 - val_loss: 1.3703 - val_accuracy: 1.0000\nEpoch 140/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.3772 - accuracy: 1.0000 - val_loss: 1.3680 - val_accuracy: 1.0000\nEpoch 141/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.3770 - accuracy: 1.0000 - val_loss: 1.3658 - val_accuracy: 1.0000\nEpoch 142/200\n5/5 [==============================] - 3s 569ms/step - loss: 1.3721 - accuracy: 1.0000 - val_loss: 1.3636 - val_accuracy: 1.0000\nEpoch 143/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.3652 - accuracy: 1.0000 - val_loss: 1.3613 - val_accuracy: 1.0000\nEpoch 144/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.3640 - accuracy: 1.0000 - val_loss: 1.3591 - val_accuracy: 1.0000\nEpoch 145/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.3627 - accuracy: 1.0000 - val_loss: 1.3568 - val_accuracy: 1.0000\nEpoch 146/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.3594 - accuracy: 1.0000 - val_loss: 1.3547 - val_accuracy: 1.0000\nEpoch 147/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.3621 - accuracy: 1.0000 - val_loss: 1.3525 - val_accuracy: 1.0000\nEpoch 148/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.3567 - accuracy: 1.0000 - val_loss: 1.3502 - val_accuracy: 1.0000\nEpoch 149/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.3590 - accuracy: 1.0000 - val_loss: 1.3480 - val_accuracy: 1.0000\nEpoch 150/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.3501 - accuracy: 1.0000 - val_loss: 1.3458 - val_accuracy: 1.0000\nEpoch 151/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.3464 - accuracy: 1.0000 - val_loss: 1.3436 - val_accuracy: 1.0000\nEpoch 152/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.3551 - accuracy: 1.0000 - val_loss: 1.3414 - val_accuracy: 1.0000\nEpoch 153/200\n5/5 [==============================] - 3s 558ms/step - loss: 1.3441 - accuracy: 1.0000 - val_loss: 1.3394 - val_accuracy: 1.0000\nEpoch 154/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.3447 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 1.0000\nEpoch 155/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.3406 - accuracy: 1.0000 - val_loss: 1.3346 - val_accuracy: 1.0000\nEpoch 156/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.3392 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 1.0000\nEpoch 157/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.3381 - accuracy: 1.0000 - val_loss: 1.3301 - val_accuracy: 1.0000\nEpoch 158/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.3341 - accuracy: 1.0000 - val_loss: 1.3278 - val_accuracy: 1.0000\nEpoch 159/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.3292 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 1.0000\nEpoch 160/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.3328 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 1.0000\nEpoch 161/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.3382 - accuracy: 0.9848 - val_loss: 1.3217 - val_accuracy: 1.0000\nEpoch 162/200\n5/5 [==============================] - 3s 538ms/step - loss: 1.3263 - accuracy: 1.0000 - val_loss: 1.3247 - val_accuracy: 1.0000\nEpoch 163/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.3276 - accuracy: 1.0000 - val_loss: 1.3286 - val_accuracy: 1.0000\nEpoch 164/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.3260 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 1.0000\nEpoch 165/200\n5/5 [==============================] - 3s 571ms/step - loss: 1.3309 - accuracy: 1.0000 - val_loss: 1.3278 - val_accuracy: 1.0000\nEpoch 166/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.3271 - accuracy: 1.0000 - val_loss: 1.3233 - val_accuracy: 1.0000\nEpoch 167/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.3257 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 1.0000\nEpoch 168/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.3177 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 1.0000\nEpoch 169/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.3101 - accuracy: 1.0000 - val_loss: 1.3110 - val_accuracy: 1.0000\nEpoch 170/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.3135 - accuracy: 1.0000 - val_loss: 1.3077 - val_accuracy: 1.0000\nEpoch 171/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.3062 - accuracy: 1.0000 - val_loss: 1.3046 - val_accuracy: 1.0000\nEpoch 172/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.3172 - accuracy: 0.9848 - val_loss: 1.3013 - val_accuracy: 1.0000\nEpoch 173/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.3105 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 1.0000\nEpoch 174/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.3029 - accuracy: 1.0000 - val_loss: 1.2956 - val_accuracy: 1.0000\nEpoch 175/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.3034 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 1.0000\nEpoch 176/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.2955 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 1.0000\nEpoch 177/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.2908 - accuracy: 1.0000 - val_loss: 1.2883 - val_accuracy: 1.0000\nEpoch 178/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.2925 - accuracy: 1.0000 - val_loss: 1.2861 - val_accuracy: 1.0000\nEpoch 179/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.2884 - accuracy: 1.0000 - val_loss: 1.2837 - val_accuracy: 1.0000\nEpoch 180/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.2856 - accuracy: 1.0000 - val_loss: 1.2816 - val_accuracy: 1.0000\nEpoch 181/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.2914 - accuracy: 1.0000 - val_loss: 1.2796 - val_accuracy: 1.0000\nEpoch 182/200\n5/5 [==============================] - 3s 531ms/step - loss: 1.3050 - accuracy: 0.9848 - val_loss: 1.2779 - val_accuracy: 1.0000\nEpoch 183/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.2785 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 1.0000\nEpoch 184/200\n5/5 [==============================] - 3s 519ms/step - loss: 1.2787 - accuracy: 1.0000 - val_loss: 1.2772 - val_accuracy: 1.0000\nEpoch 185/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.2792 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 1.0000\nEpoch 186/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.2847 - accuracy: 1.0000 - val_loss: 1.2771 - val_accuracy: 1.0000\nEpoch 187/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.2739 - accuracy: 1.0000 - val_loss: 1.2756 - val_accuracy: 1.0000\nEpoch 188/200\n5/5 [==============================] - 3s 553ms/step - loss: 1.2788 - accuracy: 1.0000 - val_loss: 1.2730 - val_accuracy: 1.0000\nEpoch 189/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.2791 - accuracy: 1.0000 - val_loss: 1.2701 - val_accuracy: 1.0000\nEpoch 190/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.2740 - accuracy: 1.0000 - val_loss: 1.2668 - val_accuracy: 1.0000\nEpoch 191/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.2694 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 1.0000\nEpoch 192/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.2636 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 1.0000\nEpoch 193/200\n5/5 [==============================] - 3s 524ms/step - loss: 1.2656 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 1.0000\nEpoch 194/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.2586 - accuracy: 1.0000 - val_loss: 1.2575 - val_accuracy: 1.0000\nEpoch 195/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.2579 - accuracy: 1.0000 - val_loss: 1.2552 - val_accuracy: 1.0000\nEpoch 196/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.2585 - accuracy: 1.0000 - val_loss: 1.2528 - val_accuracy: 1.0000\nEpoch 197/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.2587 - accuracy: 1.0000 - val_loss: 1.2504 - val_accuracy: 1.0000\nEpoch 198/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.2497 - accuracy: 1.0000 - val_loss: 1.2480 - val_accuracy: 1.0000\nEpoch 199/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.2534 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 1.0000\nEpoch 200/200\n5/5 [==============================] - 3s 548ms/step - loss: 1.2498 - accuracy: 1.0000 - val_loss: 1.2432 - val_accuracy: 1.0000\n3/3 [==============================] - 1s 156ms/step - loss: 1.2413 - accuracy: 1.0000\n1/1 [==============================] - 0s 336ms/step - loss: 1.2432 - accuracy: 1.0000\n1/1 [==============================] - 0s 284ms/step\nEpoch 1/200\n5/5 [==============================] - 3s 564ms/step - loss: 1.2452 - accuracy: 1.0000 - val_loss: 1.2391 - val_accuracy: 1.0000\nEpoch 2/200\n5/5 [==============================] - 2s 496ms/step - loss: 1.2463 - accuracy: 1.0000 - val_loss: 1.2370 - val_accuracy: 1.0000\nEpoch 3/200\n5/5 [==============================] - 3s 504ms/step - loss: 1.2463 - accuracy: 1.0000 - val_loss: 1.2349 - val_accuracy: 1.0000\nEpoch 4/200\n5/5 [==============================] - 3s 503ms/step - loss: 1.2452 - accuracy: 1.0000 - val_loss: 1.2328 - val_accuracy: 1.0000\nEpoch 5/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.2438 - accuracy: 1.0000 - val_loss: 1.2308 - val_accuracy: 1.0000\nEpoch 6/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.2531 - accuracy: 1.0000 - val_loss: 1.2291 - val_accuracy: 1.0000\nEpoch 7/200\n5/5 [==============================] - 3s 505ms/step - loss: 1.2352 - accuracy: 1.0000 - val_loss: 1.2274 - val_accuracy: 1.0000\nEpoch 8/200\n5/5 [==============================] - 2s 496ms/step - loss: 1.2348 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 1.0000\nEpoch 9/200\n5/5 [==============================] - 3s 503ms/step - loss: 1.2412 - accuracy: 1.0000 - val_loss: 1.2237 - val_accuracy: 1.0000\nEpoch 10/200\n5/5 [==============================] - 3s 511ms/step - loss: 1.2268 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 1.0000\nEpoch 11/200\n5/5 [==============================] - 3s 501ms/step - loss: 1.2220 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 1.0000\nEpoch 12/200\n5/5 [==============================] - 3s 504ms/step - loss: 1.2292 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 1.0000\nEpoch 13/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.2195 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 1.0000\nEpoch 14/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.2203 - accuracy: 1.0000 - val_loss: 1.2131 - val_accuracy: 1.0000\nEpoch 15/200\n5/5 [==============================] - 2s 497ms/step - loss: 1.2164 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 1.0000\nEpoch 16/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.2119 - accuracy: 1.0000 - val_loss: 1.2087 - val_accuracy: 1.0000\nEpoch 17/200\n5/5 [==============================] - 3s 502ms/step - loss: 1.2102 - accuracy: 1.0000 - val_loss: 1.2066 - val_accuracy: 1.0000\nEpoch 18/200\n5/5 [==============================] - 2s 497ms/step - loss: 1.2227 - accuracy: 1.0000 - val_loss: 1.2045 - val_accuracy: 1.0000\nEpoch 19/200\n5/5 [==============================] - 3s 495ms/step - loss: 1.2107 - accuracy: 1.0000 - val_loss: 1.2024 - val_accuracy: 1.0000\nEpoch 20/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.2126 - accuracy: 1.0000 - val_loss: 1.2004 - val_accuracy: 1.0000\nEpoch 21/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.2029 - accuracy: 1.0000 - val_loss: 1.1983 - val_accuracy: 1.0000\nEpoch 22/200\n5/5 [==============================] - 3s 542ms/step - loss: 1.2016 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 1.0000\nEpoch 23/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.2096 - accuracy: 0.9848 - val_loss: 1.1940 - val_accuracy: 1.0000\nEpoch 24/200\n5/5 [==============================] - 3s 509ms/step - loss: 1.2003 - accuracy: 1.0000 - val_loss: 1.1919 - val_accuracy: 1.0000\nEpoch 25/200\n5/5 [==============================] - 3s 498ms/step - loss: 1.1949 - accuracy: 1.0000 - val_loss: 1.1898 - val_accuracy: 1.0000\nEpoch 26/200\n5/5 [==============================] - 3s 500ms/step - loss: 1.1906 - accuracy: 1.0000 - val_loss: 1.1877 - val_accuracy: 1.0000\nEpoch 27/200\n5/5 [==============================] - 3s 501ms/step - loss: 1.1882 - accuracy: 1.0000 - val_loss: 1.1856 - val_accuracy: 1.0000\nEpoch 28/200\n5/5 [==============================] - 3s 498ms/step - loss: 1.1932 - accuracy: 1.0000 - val_loss: 1.1835 - val_accuracy: 1.0000\nEpoch 29/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.1912 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 1.0000\nEpoch 30/200\n5/5 [==============================] - 3s 508ms/step - loss: 1.1841 - accuracy: 1.0000 - val_loss: 1.1793 - val_accuracy: 1.0000\nEpoch 31/200\n5/5 [==============================] - 3s 511ms/step - loss: 1.1919 - accuracy: 1.0000 - val_loss: 1.1774 - val_accuracy: 1.0000\nEpoch 32/200\n5/5 [==============================] - 3s 501ms/step - loss: 1.1801 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 1.0000\nEpoch 33/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.1800 - accuracy: 1.0000 - val_loss: 1.1735 - val_accuracy: 1.0000\nEpoch 34/200\n5/5 [==============================] - 3s 541ms/step - loss: 1.1768 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 1.0000\nEpoch 35/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.1755 - accuracy: 1.0000 - val_loss: 1.1695 - val_accuracy: 1.0000\nEpoch 36/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.1763 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 1.0000\nEpoch 37/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.1711 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 1.0000\nEpoch 38/200\n5/5 [==============================] - 3s 508ms/step - loss: 1.1689 - accuracy: 1.0000 - val_loss: 1.1633 - val_accuracy: 1.0000\nEpoch 39/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.1673 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 1.0000\nEpoch 40/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.1668 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 1.0000\nEpoch 41/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.1700 - accuracy: 1.0000 - val_loss: 1.1572 - val_accuracy: 1.0000\nEpoch 42/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.1635 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 1.0000\nEpoch 43/200\n5/5 [==============================] - 3s 508ms/step - loss: 1.1648 - accuracy: 1.0000 - val_loss: 1.1532 - val_accuracy: 1.0000\nEpoch 44/200\n5/5 [==============================] - 7s 1s/step - loss: 1.1577 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 1.0000\nEpoch 45/200\n5/5 [==============================] - 6s 1s/step - loss: 1.1604 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 1.0000\nEpoch 46/200\n5/5 [==============================] - 3s 608ms/step - loss: 1.1522 - accuracy: 1.0000 - val_loss: 1.1474 - val_accuracy: 1.0000\nEpoch 47/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.1515 - accuracy: 1.0000 - val_loss: 1.1453 - val_accuracy: 1.0000\nEpoch 48/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.1479 - accuracy: 1.0000 - val_loss: 1.1433 - val_accuracy: 1.0000\nEpoch 49/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.1445 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 1.0000\nEpoch 50/200\n5/5 [==============================] - 3s 508ms/step - loss: 1.1444 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 1.0000\nEpoch 51/200\n5/5 [==============================] - 3s 499ms/step - loss: 1.1453 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 1.0000\nEpoch 52/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.1427 - accuracy: 1.0000 - val_loss: 1.1350 - val_accuracy: 1.0000\nEpoch 53/200\n5/5 [==============================] - 3s 504ms/step - loss: 1.1377 - accuracy: 1.0000 - val_loss: 1.1330 - val_accuracy: 1.0000\nEpoch 54/200\n5/5 [==============================] - 3s 506ms/step - loss: 1.1403 - accuracy: 1.0000 - val_loss: 1.1309 - val_accuracy: 1.0000\nEpoch 55/200\n5/5 [==============================] - 3s 541ms/step - loss: 1.1336 - accuracy: 1.0000 - val_loss: 1.1289 - val_accuracy: 1.0000\nEpoch 56/200\n5/5 [==============================] - 3s 505ms/step - loss: 1.1352 - accuracy: 1.0000 - val_loss: 1.1268 - val_accuracy: 1.0000\nEpoch 57/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.1336 - accuracy: 1.0000 - val_loss: 1.1248 - val_accuracy: 1.0000\nEpoch 58/200\n5/5 [==============================] - 3s 519ms/step - loss: 1.1282 - accuracy: 1.0000 - val_loss: 1.1228 - val_accuracy: 1.0000\nEpoch 59/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.1243 - accuracy: 1.0000 - val_loss: 1.1208 - val_accuracy: 1.0000\nEpoch 60/200\n5/5 [==============================] - 3s 501ms/step - loss: 1.1265 - accuracy: 1.0000 - val_loss: 1.1187 - val_accuracy: 1.0000\nEpoch 61/200\n5/5 [==============================] - 3s 507ms/step - loss: 1.1234 - accuracy: 1.0000 - val_loss: 1.1167 - val_accuracy: 1.0000\nEpoch 62/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.1208 - accuracy: 1.0000 - val_loss: 1.1146 - val_accuracy: 1.0000\nEpoch 63/200\n5/5 [==============================] - 3s 502ms/step - loss: 1.1182 - accuracy: 1.0000 - val_loss: 1.1126 - val_accuracy: 1.0000\nEpoch 64/200\n5/5 [==============================] - 3s 509ms/step - loss: 1.1192 - accuracy: 1.0000 - val_loss: 1.1106 - val_accuracy: 1.0000\nEpoch 65/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.1154 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 1.0000\nEpoch 66/200\n5/5 [==============================] - 3s 512ms/step - loss: 1.1106 - accuracy: 1.0000 - val_loss: 1.1066 - val_accuracy: 1.0000\nEpoch 67/200\n5/5 [==============================] - 3s 542ms/step - loss: 1.1067 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 1.0000\nEpoch 68/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.1116 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 1.0000\nEpoch 69/200\n5/5 [==============================] - 3s 519ms/step - loss: 1.1028 - accuracy: 1.0000 - val_loss: 1.1007 - val_accuracy: 1.0000\nEpoch 70/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.1041 - accuracy: 1.0000 - val_loss: 1.0987 - val_accuracy: 1.0000\nEpoch 71/200\n5/5 [==============================] - 3s 514ms/step - loss: 1.1002 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 1.0000\nEpoch 72/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.0998 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 1.0000\nEpoch 73/200\n5/5 [==============================] - 3s 514ms/step - loss: 1.0980 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 1.0000\nEpoch 74/200\n5/5 [==============================] - 3s 510ms/step - loss: 1.0936 - accuracy: 1.0000 - val_loss: 1.0905 - val_accuracy: 1.0000\nEpoch 75/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.0913 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 1.0000\nEpoch 76/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.0931 - accuracy: 1.0000 - val_loss: 1.0864 - val_accuracy: 1.0000\nEpoch 77/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.0875 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 1.0000\nEpoch 78/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.0869 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 1.0000\nEpoch 79/200\n5/5 [==============================] - 3s 553ms/step - loss: 1.0840 - accuracy: 1.0000 - val_loss: 1.0804 - val_accuracy: 1.0000\nEpoch 80/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.0840 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 1.0000\nEpoch 81/200\n5/5 [==============================] - 3s 512ms/step - loss: 1.0801 - accuracy: 1.0000 - val_loss: 1.0788 - val_accuracy: 1.0000\nEpoch 82/200\n5/5 [==============================] - 3s 515ms/step - loss: 1.0857 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 1.0000\nEpoch 83/200\n5/5 [==============================] - 3s 517ms/step - loss: 1.0761 - accuracy: 1.0000 - val_loss: 1.0773 - val_accuracy: 1.0000\nEpoch 84/200\n5/5 [==============================] - 3s 512ms/step - loss: 1.0798 - accuracy: 1.0000 - val_loss: 1.0758 - val_accuracy: 1.0000\nEpoch 85/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.0747 - accuracy: 1.0000 - val_loss: 1.0739 - val_accuracy: 1.0000\nEpoch 86/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.0717 - accuracy: 1.0000 - val_loss: 1.0718 - val_accuracy: 1.0000\nEpoch 87/200\n5/5 [==============================] - 3s 519ms/step - loss: 1.0739 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 1.0000\nEpoch 88/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.0659 - accuracy: 1.0000 - val_loss: 1.0670 - val_accuracy: 1.0000\nEpoch 89/200\n5/5 [==============================] - 3s 514ms/step - loss: 1.0812 - accuracy: 0.9848 - val_loss: 1.0651 - val_accuracy: 1.0000\nEpoch 90/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.0631 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 1.0000\nEpoch 91/200\n5/5 [==============================] - 3s 553ms/step - loss: 1.0616 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 1.0000\nEpoch 92/200\n5/5 [==============================] - 3s 516ms/step - loss: 1.0657 - accuracy: 1.0000 - val_loss: 1.0578 - val_accuracy: 1.0000\nEpoch 93/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.0563 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 1.0000\nEpoch 94/200\n5/5 [==============================] - 3s 521ms/step - loss: 1.0580 - accuracy: 1.0000 - val_loss: 1.0534 - val_accuracy: 1.0000\nEpoch 95/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.0556 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 1.0000\nEpoch 96/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.0517 - accuracy: 1.0000 - val_loss: 1.0490 - val_accuracy: 1.0000\nEpoch 97/200\n5/5 [==============================] - 3s 518ms/step - loss: 1.0526 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 1.0000\nEpoch 98/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.0490 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 1.0000\nEpoch 99/200\n5/5 [==============================] - 3s 513ms/step - loss: 1.0464 - accuracy: 1.0000 - val_loss: 1.0429 - val_accuracy: 1.0000\nEpoch 100/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.0448 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 1.0000\nEpoch 101/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.0496 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 1.0000\nEpoch 102/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.0393 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 1.0000\nEpoch 103/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.0396 - accuracy: 1.0000 - val_loss: 1.0345 - val_accuracy: 1.0000\nEpoch 104/200\n5/5 [==============================] - 3s 519ms/step - loss: 1.0420 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 1.0000\nEpoch 105/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.0355 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 1.0000\nEpoch 106/200\n5/5 [==============================] - 3s 530ms/step - loss: 1.0342 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 1.0000\nEpoch 107/200\n5/5 [==============================] - 3s 529ms/step - loss: 1.0283 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 1.0000\nEpoch 108/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.0299 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 1.0000\nEpoch 109/200\n5/5 [==============================] - 3s 514ms/step - loss: 1.0253 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 1.0000\nEpoch 110/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.0261 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 1.0000\nEpoch 111/200\n5/5 [==============================] - 3s 520ms/step - loss: 1.0341 - accuracy: 0.9848 - val_loss: 1.0185 - val_accuracy: 1.0000\nEpoch 112/200\n5/5 [==============================] - 3s 522ms/step - loss: 1.0192 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 1.0000\nEpoch 113/200\n5/5 [==============================] - 3s 535ms/step - loss: 1.0198 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 1.0000\nEpoch 114/200\n5/5 [==============================] - 3s 576ms/step - loss: 1.0177 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 1.0000\nEpoch 115/200\n5/5 [==============================] - 3s 527ms/step - loss: 1.0133 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 1.0000\nEpoch 116/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.0119 - accuracy: 1.0000 - val_loss: 1.0091 - val_accuracy: 1.0000\nEpoch 117/200\n5/5 [==============================] - 3s 537ms/step - loss: 1.0090 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 1.0000\nEpoch 118/200\n5/5 [==============================] - 3s 523ms/step - loss: 1.0076 - accuracy: 1.0000 - val_loss: 1.0051 - val_accuracy: 1.0000\nEpoch 119/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.0088 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 1.0000\nEpoch 120/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.0289 - accuracy: 0.9848 - val_loss: 1.0010 - val_accuracy: 1.0000\nEpoch 121/200\n5/5 [==============================] - 3s 532ms/step - loss: 1.0029 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 1.0000\nEpoch 122/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.0098 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 1.0000\nEpoch 123/200\n5/5 [==============================] - 3s 528ms/step - loss: 1.0203 - accuracy: 1.0000 - val_loss: 1.0049 - val_accuracy: 1.0000\nEpoch 124/200\n5/5 [==============================] - 3s 526ms/step - loss: 1.0149 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 1.0000\nEpoch 125/200\n5/5 [==============================] - 3s 534ms/step - loss: 1.0136 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 1.0000\nEpoch 126/200\n5/5 [==============================] - 3s 566ms/step - loss: 1.0577 - accuracy: 0.9697 - val_loss: 0.9948 - val_accuracy: 1.0000\nEpoch 127/200\n5/5 [==============================] - 3s 525ms/step - loss: 1.0052 - accuracy: 1.0000 - val_loss: 0.9925 - val_accuracy: 1.0000\nEpoch 128/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.9975 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 1.0000\nEpoch 129/200\n5/5 [==============================] - 3s 540ms/step - loss: 1.0000 - accuracy: 1.0000 - val_loss: 0.9897 - val_accuracy: 1.0000\nEpoch 130/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.9950 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 1.0000\nEpoch 131/200\n5/5 [==============================] - 3s 561ms/step - loss: 0.9901 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 1.0000\nEpoch 132/200\n5/5 [==============================] - 5s 950ms/step - loss: 1.0003 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 1.0000\nEpoch 133/200\n5/5 [==============================] - 4s 863ms/step - loss: 0.9855 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 1.0000\nEpoch 134/200\n5/5 [==============================] - 4s 747ms/step - loss: 0.9852 - accuracy: 1.0000 - val_loss: 0.9806 - val_accuracy: 1.0000\nEpoch 135/200\n5/5 [==============================] - 4s 877ms/step - loss: 0.9969 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 1.0000\nEpoch 136/200\n5/5 [==============================] - 5s 930ms/step - loss: 0.9814 - accuracy: 1.0000 - val_loss: 0.9774 - val_accuracy: 1.0000\nEpoch 137/200\n5/5 [==============================] - 4s 854ms/step - loss: 0.9843 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 1.0000\nEpoch 138/200\n5/5 [==============================] - 4s 882ms/step - loss: 0.9778 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 1.0000\nEpoch 139/200\n5/5 [==============================] - 4s 862ms/step - loss: 0.9833 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 1.0000\nEpoch 140/200\n5/5 [==============================] - 5s 948ms/step - loss: 0.9755 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 1.0000\nEpoch 141/200\n5/5 [==============================] - 4s 782ms/step - loss: 0.9735 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 1.0000\nEpoch 142/200\n5/5 [==============================] - 5s 985ms/step - loss: 0.9718 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 1.0000\nEpoch 143/200\n5/5 [==============================] - 4s 708ms/step - loss: 0.9709 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 1.0000\nEpoch 144/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.9660 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 1.0000\nEpoch 145/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.9638 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 1.0000\nEpoch 146/200\n5/5 [==============================] - 3s 549ms/step - loss: 0.9649 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 1.0000\nEpoch 147/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.9623 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 1.0000\nEpoch 148/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.9579 - accuracy: 1.0000 - val_loss: 0.9569 - val_accuracy: 1.0000\nEpoch 149/200\n5/5 [==============================] - 3s 541ms/step - loss: 0.9572 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 1.0000\nEpoch 150/200\n5/5 [==============================] - 3s 540ms/step - loss: 0.9553 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 1.0000\nEpoch 151/200\n5/5 [==============================] - 3s 543ms/step - loss: 0.9534 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 1.0000\nEpoch 152/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.9523 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 1.0000\nEpoch 153/200\n5/5 [==============================] - 3s 560ms/step - loss: 0.9510 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 1.0000\nEpoch 154/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.9495 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 1.0000\nEpoch 155/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.9446 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 1.0000\nEpoch 156/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.9442 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 1.0000\nEpoch 157/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.9425 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 1.0000\nEpoch 158/200\n5/5 [==============================] - 3s 543ms/step - loss: 0.9400 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 1.0000\nEpoch 159/200\n5/5 [==============================] - 3s 541ms/step - loss: 0.9382 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 1.0000\nEpoch 160/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.9400 - accuracy: 1.0000 - val_loss: 0.9353 - val_accuracy: 1.0000\nEpoch 161/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.9355 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 1.0000\nEpoch 162/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.9322 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 1.0000\nEpoch 163/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.9366 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 1.0000\nEpoch 164/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.9303 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 1.0000\nEpoch 165/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.9330 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 1.0000\nEpoch 166/200\n5/5 [==============================] - 3s 522ms/step - loss: 0.9274 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 1.0000\nEpoch 167/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.9252 - accuracy: 1.0000 - val_loss: 0.9235 - val_accuracy: 1.0000\nEpoch 168/200\n5/5 [==============================] - 3s 523ms/step - loss: 0.9239 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 1.0000\nEpoch 169/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.9203 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 1.0000\nEpoch 170/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.9195 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 1.0000\nEpoch 171/200\n5/5 [==============================] - 3s 540ms/step - loss: 0.9171 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 1.0000\nEpoch 172/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.9178 - accuracy: 1.0000 - val_loss: 0.9152 - val_accuracy: 1.0000\nEpoch 173/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.9132 - accuracy: 1.0000 - val_loss: 0.9135 - val_accuracy: 1.0000\nEpoch 174/200\n5/5 [==============================] - 3s 548ms/step - loss: 0.9114 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 1.0000\nEpoch 175/200\n5/5 [==============================] - 3s 544ms/step - loss: 0.9143 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 1.0000\nEpoch 176/200\n5/5 [==============================] - 3s 572ms/step - loss: 0.9132 - accuracy: 1.0000 - val_loss: 0.9082 - val_accuracy: 1.0000\nEpoch 177/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.9081 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 1.0000\nEpoch 178/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.9065 - accuracy: 1.0000 - val_loss: 0.9047 - val_accuracy: 1.0000\nEpoch 179/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.9050 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 1.0000\nEpoch 180/200\n5/5 [==============================] - 3s 545ms/step - loss: 0.9030 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 1.0000\nEpoch 181/200\n5/5 [==============================] - 3s 552ms/step - loss: 0.8996 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 1.0000\nEpoch 182/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.8981 - accuracy: 1.0000 - val_loss: 0.8981 - val_accuracy: 1.0000\nEpoch 183/200\n5/5 [==============================] - 3s 552ms/step - loss: 0.8945 - accuracy: 1.0000 - val_loss: 0.8964 - val_accuracy: 1.0000\nEpoch 184/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.8951 - accuracy: 1.0000 - val_loss: 0.8946 - val_accuracy: 1.0000\nEpoch 185/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.8934 - accuracy: 1.0000 - val_loss: 0.8928 - val_accuracy: 1.0000\nEpoch 186/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.8912 - accuracy: 1.0000 - val_loss: 0.8909 - val_accuracy: 1.0000\nEpoch 187/200\n5/5 [==============================] - 3s 556ms/step - loss: 0.8894 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 1.0000\nEpoch 188/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.8888 - accuracy: 1.0000 - val_loss: 0.8872 - val_accuracy: 1.0000\nEpoch 189/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.8845 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 1.0000\nEpoch 190/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.8843 - accuracy: 1.0000 - val_loss: 0.8835 - val_accuracy: 1.0000\nEpoch 191/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.8938 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 1.0000\nEpoch 192/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.8825 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 1.0000\nEpoch 193/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.8790 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 1.0000\nEpoch 194/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.8756 - accuracy: 1.0000 - val_loss: 0.8758 - val_accuracy: 1.0000\nEpoch 195/200\n5/5 [==============================] - 3s 548ms/step - loss: 0.8741 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 1.0000\nEpoch 196/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.8760 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 1.0000\nEpoch 197/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.8728 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 1.0000\nEpoch 198/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.8689 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 1.0000\nEpoch 199/200\n5/5 [==============================] - 3s 573ms/step - loss: 0.8682 - accuracy: 1.0000 - val_loss: 0.8677 - val_accuracy: 1.0000\nEpoch 200/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.8696 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 1.0000\n3/3 [==============================] - 2s 155ms/step - loss: 0.8628 - accuracy: 1.0000\n1/1 [==============================] - 0s 247ms/step - loss: 0.8662 - accuracy: 1.0000\n1/1 [==============================] - 0s 245ms/step\nEpoch 1/200\n5/5 [==============================] - 4s 685ms/step - loss: 0.8651 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 1.0000\nEpoch 2/200\n5/5 [==============================] - 3s 513ms/step - loss: 0.8629 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 1.0000\nEpoch 3/200\n5/5 [==============================] - 3s 515ms/step - loss: 0.8654 - accuracy: 1.0000 - val_loss: 0.8576 - val_accuracy: 1.0000\nEpoch 4/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.8626 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 1.0000\nEpoch 5/200\n5/5 [==============================] - 3s 521ms/step - loss: 0.8569 - accuracy: 1.0000 - val_loss: 0.8541 - val_accuracy: 1.0000\nEpoch 6/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.8558 - accuracy: 1.0000 - val_loss: 0.8524 - val_accuracy: 1.0000\nEpoch 7/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.8569 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 1.0000\nEpoch 8/200\n5/5 [==============================] - 3s 555ms/step - loss: 0.8536 - accuracy: 1.0000 - val_loss: 0.8489 - val_accuracy: 1.0000\nEpoch 9/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.8551 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 1.0000\nEpoch 10/200\n5/5 [==============================] - 3s 512ms/step - loss: 0.8503 - accuracy: 1.0000 - val_loss: 0.8454 - val_accuracy: 1.0000\nEpoch 11/200\n5/5 [==============================] - 3s 516ms/step - loss: 0.8505 - accuracy: 1.0000 - val_loss: 0.8437 - val_accuracy: 1.0000\nEpoch 12/200\n5/5 [==============================] - 3s 521ms/step - loss: 0.8548 - accuracy: 1.0000 - val_loss: 0.8420 - val_accuracy: 1.0000\nEpoch 13/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.8439 - accuracy: 1.0000 - val_loss: 0.8403 - val_accuracy: 1.0000\nEpoch 14/200\n5/5 [==============================] - 3s 516ms/step - loss: 0.8458 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 1.0000\nEpoch 15/200\n5/5 [==============================] - 3s 517ms/step - loss: 0.8420 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 1.0000\nEpoch 16/200\n5/5 [==============================] - 3s 507ms/step - loss: 0.8472 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 1.0000\nEpoch 17/200\n5/5 [==============================] - 3s 521ms/step - loss: 0.8555 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 1.0000\nEpoch 18/200\n5/5 [==============================] - 3s 522ms/step - loss: 0.8461 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 1.0000\nEpoch 19/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.8348 - accuracy: 1.0000 - val_loss: 0.8317 - val_accuracy: 1.0000\nEpoch 20/200\n5/5 [==============================] - 3s 524ms/step - loss: 0.8402 - accuracy: 1.0000 - val_loss: 0.8302 - val_accuracy: 1.0000\nEpoch 21/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.8338 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 1.0000\nEpoch 22/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.8314 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 1.0000\nEpoch 23/200\n5/5 [==============================] - 3s 522ms/step - loss: 0.8335 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 1.0000\nEpoch 24/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.8310 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 1.0000\nEpoch 25/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.8268 - accuracy: 1.0000 - val_loss: 0.8221 - val_accuracy: 1.0000\nEpoch 26/200\n5/5 [==============================] - 3s 517ms/step - loss: 0.8237 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 1.0000\nEpoch 27/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.8223 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 1.0000\nEpoch 28/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.8213 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 1.0000\nEpoch 29/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.8211 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 1.0000\nEpoch 30/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.8169 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 1.0000\nEpoch 31/200\n5/5 [==============================] - 3s 551ms/step - loss: 0.8175 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 1.0000\nEpoch 32/200\n5/5 [==============================] - 3s 511ms/step - loss: 0.8151 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 1.0000\nEpoch 33/200\n5/5 [==============================] - 3s 519ms/step - loss: 0.8109 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 1.0000\nEpoch 34/200\n5/5 [==============================] - 3s 517ms/step - loss: 0.8123 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 1.0000\nEpoch 35/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.8082 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 1.0000\nEpoch 36/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.8075 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 1.0000\nEpoch 37/200\n5/5 [==============================] - 3s 523ms/step - loss: 0.8117 - accuracy: 1.0000 - val_loss: 0.8024 - val_accuracy: 1.0000\nEpoch 38/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.8059 - accuracy: 1.0000 - val_loss: 0.8007 - val_accuracy: 1.0000\nEpoch 39/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.8031 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 1.0000\nEpoch 40/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.8020 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 1.0000\nEpoch 41/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.7977 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 1.0000\nEpoch 42/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.7972 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 1.0000\nEpoch 43/200\n5/5 [==============================] - 3s 553ms/step - loss: 0.7963 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 1.0000\nEpoch 44/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.7942 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 1.0000\nEpoch 45/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.7914 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 1.0000\nEpoch 46/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.7890 - accuracy: 1.0000 - val_loss: 0.7876 - val_accuracy: 1.0000\nEpoch 47/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.7884 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 1.0000\nEpoch 48/200\n5/5 [==============================] - 3s 521ms/step - loss: 0.7861 - accuracy: 1.0000 - val_loss: 0.7843 - val_accuracy: 1.0000\nEpoch 49/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.7892 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 1.0000\nEpoch 50/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.7842 - accuracy: 1.0000 - val_loss: 0.7809 - val_accuracy: 1.0000\nEpoch 51/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.7828 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 1.0000\nEpoch 52/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.7808 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 1.0000\nEpoch 53/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.7779 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 1.0000\nEpoch 54/200\n5/5 [==============================] - 3s 560ms/step - loss: 0.7767 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 1.0000\nEpoch 55/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.7787 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 1.0000\nEpoch 56/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.7731 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 1.0000\nEpoch 57/200\n5/5 [==============================] - 3s 523ms/step - loss: 0.7713 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 1.0000\nEpoch 58/200\n5/5 [==============================] - 3s 540ms/step - loss: 0.7728 - accuracy: 1.0000 - val_loss: 0.7679 - val_accuracy: 1.0000\nEpoch 59/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.7688 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 1.0000\nEpoch 60/200\n5/5 [==============================] - 3s 518ms/step - loss: 0.7669 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 1.0000\nEpoch 61/200\n5/5 [==============================] - 6s 1s/step - loss: 0.7666 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 1.0000\nEpoch 62/200\n5/5 [==============================] - 6s 1s/step - loss: 0.7631 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 1.0000\nEpoch 63/200\n5/5 [==============================] - 5s 967ms/step - loss: 0.7636 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 1.0000\nEpoch 64/200\n5/5 [==============================] - 3s 581ms/step - loss: 0.7600 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 1.0000\nEpoch 65/200\n5/5 [==============================] - 3s 551ms/step - loss: 0.7588 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 1.0000\nEpoch 66/200\n5/5 [==============================] - 3s 547ms/step - loss: 0.7585 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 1.0000\nEpoch 67/200\n5/5 [==============================] - 3s 547ms/step - loss: 0.7554 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 1.0000\nEpoch 68/200\n5/5 [==============================] - 3s 546ms/step - loss: 0.7557 - accuracy: 1.0000 - val_loss: 0.7523 - val_accuracy: 1.0000\nEpoch 69/200\n5/5 [==============================] - 3s 545ms/step - loss: 0.7519 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 1.0000\nEpoch 70/200\n5/5 [==============================] - 3s 544ms/step - loss: 0.7503 - accuracy: 1.0000 - val_loss: 0.7490 - val_accuracy: 1.0000\nEpoch 71/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.7500 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 1.0000\nEpoch 72/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.7491 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 1.0000\nEpoch 73/200\n5/5 [==============================] - 3s 524ms/step - loss: 0.7515 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 1.0000\nEpoch 74/200\n5/5 [==============================] - 3s 564ms/step - loss: 0.7437 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 1.0000\nEpoch 75/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.7440 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 1.0000\nEpoch 76/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.7408 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 1.0000\nEpoch 77/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.7385 - accuracy: 1.0000 - val_loss: 0.7368 - val_accuracy: 1.0000\nEpoch 78/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.7370 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 1.0000\nEpoch 79/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.7354 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 1.0000\nEpoch 80/200\n5/5 [==============================] - 3s 521ms/step - loss: 0.7336 - accuracy: 1.0000 - val_loss: 0.7319 - val_accuracy: 1.0000\nEpoch 81/200\n5/5 [==============================] - 3s 519ms/step - loss: 0.7328 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 1.0000\nEpoch 82/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.7307 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 1.0000\nEpoch 83/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.7310 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 1.0000\nEpoch 84/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.7292 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 1.0000\nEpoch 85/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.7281 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 1.0000\nEpoch 86/200\n5/5 [==============================] - 3s 542ms/step - loss: 0.7251 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 1.0000\nEpoch 87/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.7231 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 1.0000\nEpoch 88/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.7218 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 1.0000\nEpoch 89/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.7215 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 1.0000\nEpoch 90/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.7175 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 1.0000\nEpoch 91/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.7185 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 1.0000\nEpoch 92/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.7148 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 1.0000\nEpoch 93/200\n5/5 [==============================] - 3s 522ms/step - loss: 0.7141 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 1.0000\nEpoch 94/200\n5/5 [==============================] - 3s 545ms/step - loss: 0.7114 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 1.0000\nEpoch 95/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.7103 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 1.0000\nEpoch 96/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.7096 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 1.0000\nEpoch 97/200\n5/5 [==============================] - 3s 556ms/step - loss: 0.7074 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 1.0000\nEpoch 98/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.7064 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 1.0000\nEpoch 99/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.7057 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 1.0000\nEpoch 100/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.7021 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 1.0000\nEpoch 101/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.7004 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 1.0000\nEpoch 102/200\n5/5 [==============================] - 3s 523ms/step - loss: 0.6997 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 1.0000\nEpoch 103/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.7049 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 1.0000\nEpoch 104/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.6962 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 1.0000\nEpoch 105/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.6958 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 1.0000\nEpoch 106/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.6933 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 1.0000\nEpoch 107/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.6909 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 1.0000\nEpoch 108/200\n5/5 [==============================] - 3s 546ms/step - loss: 0.6910 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 1.0000\nEpoch 109/200\n5/5 [==============================] - 3s 553ms/step - loss: 0.6891 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 1.0000\nEpoch 110/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.6870 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 1.0000\nEpoch 111/200\n5/5 [==============================] - 3s 521ms/step - loss: 0.6846 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 1.0000\nEpoch 112/200\n5/5 [==============================] - 3s 540ms/step - loss: 0.6833 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 1.0000\nEpoch 113/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.6836 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 1.0000\nEpoch 114/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.6825 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 1.0000\nEpoch 115/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.6782 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 1.0000\nEpoch 116/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.6769 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 1.0000\nEpoch 117/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.6759 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 1.0000\nEpoch 118/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.6749 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 1.0000\nEpoch 119/200\n5/5 [==============================] - 3s 523ms/step - loss: 0.6735 - accuracy: 1.0000 - val_loss: 0.6703 - val_accuracy: 1.0000\nEpoch 120/200\n5/5 [==============================] - 3s 547ms/step - loss: 0.6709 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 1.0000\nEpoch 121/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.6722 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 1.0000\nEpoch 122/200\n5/5 [==============================] - 3s 520ms/step - loss: 0.6680 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 1.0000\nEpoch 123/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.6662 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 1.0000\nEpoch 124/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.6644 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 1.0000\nEpoch 125/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.6628 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 1.0000\nEpoch 126/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.6619 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 1.0000\nEpoch 127/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.6606 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 1.0000\nEpoch 128/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.6582 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 1.0000\nEpoch 129/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.6571 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 1.0000\nEpoch 130/200\n5/5 [==============================] - 3s 519ms/step - loss: 0.6556 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 1.0000\nEpoch 131/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.6629 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 1.0000\nEpoch 132/200\n5/5 [==============================] - 3s 564ms/step - loss: 0.6521 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 1.0000\nEpoch 133/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.6515 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 1.0000\nEpoch 134/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.6510 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 1.0000\nEpoch 135/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.6551 - accuracy: 1.0000 - val_loss: 0.6457 - val_accuracy: 1.0000\nEpoch 136/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.6460 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 1.0000\nEpoch 137/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.6449 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 1.0000\nEpoch 138/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.6451 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 1.0000\nEpoch 139/200\n5/5 [==============================] - 3s 527ms/step - loss: 0.6435 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 1.0000\nEpoch 140/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.6405 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 1.0000\nEpoch 141/200\n5/5 [==============================] - 3s 542ms/step - loss: 0.6407 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 1.0000\nEpoch 142/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.6368 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 1.0000\nEpoch 143/200\n5/5 [==============================] - 3s 547ms/step - loss: 0.6361 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 1.0000\nEpoch 144/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.6351 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 1.0000\nEpoch 145/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.6330 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 1.0000\nEpoch 146/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.6330 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 1.0000\nEpoch 147/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.6296 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 1.0000\nEpoch 148/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.6285 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 1.0000\nEpoch 149/200\n5/5 [==============================] - 3s 522ms/step - loss: 0.6271 - accuracy: 1.0000 - val_loss: 0.6250 - val_accuracy: 1.0000\nEpoch 150/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.6249 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 1.0000\nEpoch 151/200\n5/5 [==============================] - 3s 526ms/step - loss: 0.6251 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 1.0000\nEpoch 152/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.6227 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 1.0000\nEpoch 153/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.6212 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 1.0000\nEpoch 154/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.6195 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 1.0000\nEpoch 155/200\n5/5 [==============================] - 3s 573ms/step - loss: 0.6180 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 1.0000\nEpoch 156/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.6177 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 1.0000\nEpoch 157/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.6150 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 1.0000\nEpoch 158/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.6170 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 1.0000\nEpoch 159/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.6147 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 1.0000\nEpoch 160/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.6115 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 1.0000\nEpoch 161/200\n5/5 [==============================] - 3s 540ms/step - loss: 0.6089 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 1.0000\nEpoch 162/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.6085 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 1.0000\nEpoch 163/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.6066 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 1.0000\nEpoch 164/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.6046 - accuracy: 1.0000 - val_loss: 0.6031 - val_accuracy: 1.0000\nEpoch 165/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.6027 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 1.0000\nEpoch 166/200\n5/5 [==============================] - 3s 546ms/step - loss: 0.6015 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 1.0000\nEpoch 167/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.6017 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 1.0000\nEpoch 168/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.5983 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 1.0000\nEpoch 169/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.5986 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 1.0000\nEpoch 170/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.5961 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 1.0000\nEpoch 171/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.5952 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 1.0000\nEpoch 172/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.5925 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 1.0000\nEpoch 173/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.5926 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 1.0000\nEpoch 174/200\n5/5 [==============================] - 3s 536ms/step - loss: 0.5900 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 1.0000\nEpoch 175/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.5904 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 1.0000\nEpoch 176/200\n5/5 [==============================] - 3s 530ms/step - loss: 0.5872 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 1.0000\nEpoch 177/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.5862 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 1.0000\nEpoch 178/200\n5/5 [==============================] - 3s 571ms/step - loss: 0.5846 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 1.0000\nEpoch 179/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.5837 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 1.0000\nEpoch 180/200\n5/5 [==============================] - 3s 537ms/step - loss: 0.5806 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 1.0000\nEpoch 181/200\n5/5 [==============================] - 3s 539ms/step - loss: 0.5801 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 1.0000\nEpoch 182/200\n5/5 [==============================] - 3s 541ms/step - loss: 0.5779 - accuracy: 1.0000 - val_loss: 0.5772 - val_accuracy: 1.0000\nEpoch 183/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.5772 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 1.0000\nEpoch 184/200\n5/5 [==============================] - 3s 524ms/step - loss: 0.5747 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 1.0000\nEpoch 185/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.5737 - accuracy: 1.0000 - val_loss: 0.5729 - val_accuracy: 1.0000\nEpoch 186/200\n5/5 [==============================] - 3s 542ms/step - loss: 0.5753 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 1.0000\nEpoch 187/200\n5/5 [==============================] - 3s 541ms/step - loss: 0.5709 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 1.0000\nEpoch 188/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.5696 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 1.0000\nEpoch 189/200\n5/5 [==============================] - 3s 546ms/step - loss: 0.5696 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 1.0000\nEpoch 190/200\n5/5 [==============================] - 3s 538ms/step - loss: 0.5671 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 1.0000\nEpoch 191/200\n5/5 [==============================] - 3s 545ms/step - loss: 0.5652 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 1.0000\nEpoch 192/200\n5/5 [==============================] - 3s 525ms/step - loss: 0.5667 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 1.0000\nEpoch 193/200\n5/5 [==============================] - 3s 532ms/step - loss: 0.5641 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 1.0000\nEpoch 194/200\n5/5 [==============================] - 3s 545ms/step - loss: 0.5634 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 1.0000\nEpoch 195/200\n5/5 [==============================] - 3s 535ms/step - loss: 0.5604 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 1.0000\nEpoch 196/200\n5/5 [==============================] - 3s 528ms/step - loss: 0.5597 - accuracy: 1.0000 - val_loss: 0.5580 - val_accuracy: 1.0000\nEpoch 197/200\n5/5 [==============================] - 3s 533ms/step - loss: 0.5567 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 1.0000\nEpoch 198/200\n5/5 [==============================] - 3s 534ms/step - loss: 0.5553 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 1.0000\nEpoch 199/200\n5/5 [==============================] - 3s 531ms/step - loss: 0.5549 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 1.0000\nEpoch 200/200\n5/5 [==============================] - 3s 529ms/step - loss: 0.5562 - accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 1.0000\n3/3 [==============================] - 1s 158ms/step - loss: 0.5503 - accuracy: 1.0000\n1/1 [==============================] - 0s 250ms/step - loss: 0.5528 - accuracy: 1.0000\n1/1 [==============================] - 0s 240ms/step\nConfusion Matrix\n[[4.66666667 0.33333333]\n [0.33333333 7.83333333]]\n\n\nClassification Report\n              precision    recall  f1-score   support\n\n     Control       0.37      0.37      0.37        30\n   Concussed       0.61      0.61      0.61        49\n\n    accuracy                           0.52        79\n   macro avg       0.49      0.49      0.49        79\nweighted avg       0.52      0.52      0.52        79\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the average accuracies\navg_train_accuracy = np.mean(train_accuracies)\navg_val_accuracy = np.mean(val_accuracies)\n\nprint('Average Training Accuracy:', avg_train_accuracy)\nprint('Average Validation Accuracy:', avg_val_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:58:34.374443Z","iopub.execute_input":"2023-06-11T14:58:34.375031Z","iopub.status.idle":"2023-06-11T14:58:34.385208Z","shell.execute_reply.started":"2023-06-11T14:58:34.375005Z","shell.execute_reply":"2023-06-11T14:58:34.384041Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Average Training Accuracy: 1.0\nAverage Validation Accuracy: 0.9523809552192688\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training and validation accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot training and validation loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:58:34.391908Z","iopub.execute_input":"2023-06-11T14:58:34.392280Z","iopub.status.idle":"2023-06-11T14:58:35.086251Z","shell.execute_reply.started":"2023-06-11T14:58:34.392257Z","shell.execute_reply":"2023-06-11T14:58:35.084892Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\ntarget_names = ['Normal', 'Concussed']\nprint('Confusion Matrix')\ncm = confusion_matrix(true_labels, predicted_labels)\nprint(cm)\nprint('\\n')\n\nprint('Classification Report')\nprint(classification_report(true_labels, predicted_labels, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2023-06-11T14:58:35.088023Z","iopub.execute_input":"2023-06-11T14:58:35.088373Z","iopub.status.idle":"2023-06-11T14:58:35.810686Z","shell.execute_reply.started":"2023-06-11T14:58:35.088348Z","shell.execute_reply":"2023-06-11T14:58:35.808896Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Confusion Matrix\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcussed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mtrue_labels\u001b[49m, predicted_labels)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'true_labels' is not defined"],"ename":"NameError","evalue":"name 'true_labels' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}